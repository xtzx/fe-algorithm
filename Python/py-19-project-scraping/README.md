# P19: ç»¼åˆé¡¹ç›® - æŠ€æœ¯åšå®¢èšåˆå™¨

> ç»¼åˆè¿ç”¨ç½‘ç»œå’Œå¹¶å‘çŸ¥è¯†ï¼Œå®Œæˆæ•°æ®é‡‡é›†é¡¹ç›®

## ğŸ¯ é¡¹ç›®ç›®æ ‡

å¼€å‘ä¸€ä¸ªã€ŒæŠ€æœ¯åšå®¢èšåˆå™¨ã€ï¼š
- ä»å¤šä¸ªæŠ€æœ¯åšå®¢æŠ“å–æ–‡ç« åˆ—è¡¨
- å¼‚æ­¥å¹¶å‘æé«˜æ•ˆç‡
- æ•°æ®æ¸…æ´—ä¸ç»“æ„åŒ–
- ç”ŸæˆèšåˆæŠ¥å‘Š
- å¢é‡æ›´æ–°ï¼ˆåªæŠ“æ–°æ–‡ç« ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd py-19-project-scraping

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œé‡‡é›†
python -m blog_aggregator collect --all

# ç”ŸæˆæŠ¥å‘Š
python -m blog_aggregator report
```

## ğŸ“ ç›®å½•ç»“æ„

```
py-19-project-scraping/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ config.toml                    # é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/blog_aggregator/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                  # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ sources/                   # åšå®¢æºè§£æå™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py               # åŸºç±»
â”‚   â”‚   â”œâ”€â”€ dev_to.py             # DEV.to
â”‚   â”‚   â”œâ”€â”€ hashnode.py           # Hashnode
â”‚   â”‚   â””â”€â”€ medium.py             # Mediumï¼ˆç¤ºä¾‹ï¼‰
â”‚   â”œâ”€â”€ fetcher.py                 # å¹¶å‘è·å–å™¨
â”‚   â”œâ”€â”€ pipeline.py                # æ•°æ®ç®¡é“
â”‚   â”œâ”€â”€ storage.py                 # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ reporter.py                # æŠ¥å‘Šç”Ÿæˆ
â”‚   â””â”€â”€ cli.py                     # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ fixtures/
â”‚   â””â”€â”€ test_*.py
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ articles.jsonl            # æ–‡ç« å­˜å‚¨
â”‚   â””â”€â”€ state.json                # çŠ¶æ€æ–‡ä»¶
â””â”€â”€ scripts/
    â””â”€â”€ run_demo.sh
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. å¤šæºæŠ“å–

```python
from blog_aggregator import BlogAggregator

aggregator = BlogAggregator()

# æŠ“å–æ‰€æœ‰é…ç½®çš„æº
articles = await aggregator.collect_all()

# æŠ“å–ç‰¹å®šæº
articles = await aggregator.collect(sources=["dev_to", "hashnode"])
```

### 2. å¹¶å‘æ§åˆ¶

```python
from blog_aggregator import Fetcher

fetcher = Fetcher(
    max_concurrent=10,           # å…¨å±€æœ€å¤§å¹¶å‘
    per_host_limit=3,            # æ¯ä¸ªç«™ç‚¹æœ€å¤§å¹¶å‘
    rate_limit=2.0,              # æ¯ç§’è¯·æ±‚æ•°
)
```

### 3. æ•°æ®æ¨¡å‹

```python
from blog_aggregator.models import Article

article = Article(
    id="unique-id",
    title="Python Async Programming",
    url="https://dev.to/...",
    source="dev_to",
    author="John Doe",
    published_at=datetime.now(),
    tags=["python", "async"],
)
```

### 4. å¢é‡æ›´æ–°

```python
# åªæŠ“å–æ–°æ–‡ç« 
articles = await aggregator.collect_all(incremental=True)
```

### 5. æŠ¥å‘Šç”Ÿæˆ

```bash
# ç”Ÿæˆ Markdown æŠ¥å‘Š
python -m blog_aggregator report --format markdown --output report.md

# ç”Ÿæˆ JSON æŠ¥å‘Š
python -m blog_aggregator report --format json
```

## ğŸ“Š æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CLI         â”‚  å‘½ä»¤è¡Œå…¥å£
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Aggregator    â”‚  åè°ƒå™¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚Sourcesâ”‚ â”‚Fetcherâ”‚  å¤šæºè§£æ + å¹¶å‘è·å–
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Pipeline     â”‚  æ•°æ®æ¸…æ´—å’ŒéªŒè¯
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Storage      â”‚  æŒä¹…åŒ– (JSONL)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ é…ç½®

### config.toml

```toml
[general]
data_dir = "data"
max_concurrent = 10
rate_limit = 2.0

[sources.dev_to]
enabled = true
base_url = "https://dev.to"
per_page = 30

[sources.hashnode]
enabled = true
base_url = "https://hashnode.com"
```

## ğŸ“ å‘½ä»¤è¡Œä½¿ç”¨

```bash
# é‡‡é›†æ‰€æœ‰å¯ç”¨çš„æº
python -m blog_aggregator collect --all

# é‡‡é›†ç‰¹å®šæº
python -m blog_aggregator collect --source dev_to

# å¢é‡é‡‡é›†ï¼ˆåªæŠ“æ–°æ–‡ç« ï¼‰
python -m blog_aggregator collect --all --incremental

# æŸ¥çœ‹çŠ¶æ€
python -m blog_aggregator status

# ç”ŸæˆæŠ¥å‘Š
python -m blog_aggregator report --format markdown
```

## ğŸ§ª çŸ¥è¯†åº”ç”¨

| çŸ¥è¯†ç‚¹ | åº”ç”¨ |
|--------|------|
| P16 HTTP å®¢æˆ·ç«¯ | httpx å¼‚æ­¥è¯·æ±‚ã€é‡è¯•ã€è¶…æ—¶ |
| P17 asyncio | å¹¶å‘æ§åˆ¶ã€TaskGroupã€Semaphore |
| P18 çˆ¬è™«å·¥ç¨‹ | è§£æã€å»é‡ã€æ–­ç‚¹ç»­çˆ¬ã€robots.txt |
| P12 æ•°æ®æ¨¡å‹ | pydantic éªŒè¯ã€æ•°æ®æ¸…æ´— |
| P13 æ–‡ä»¶è‡ªåŠ¨åŒ– | å¢é‡å¤„ç†ã€çŠ¶æ€ç®¡ç† |

## âœ… åŠŸèƒ½æ¸…å•

- [x] å¤šæºæŠ“å–ï¼ˆ3+ åšå®¢æºï¼‰
- [x] ç»Ÿä¸€æ•°æ®æ¨¡å‹
- [x] asyncio å¹¶å‘
- [x] æ¯ç«™ç‚¹å¹¶å‘é™åˆ¶
- [x] å…¨å±€é€Ÿç‡é™åˆ¶
- [x] pydantic æ¨¡å‹éªŒè¯
- [x] æ•°æ®æ¸…æ´—ä¸è§„èŒƒåŒ–
- [x] URL å»é‡
- [x] å¢é‡æ›´æ–°
- [x] JSONL å­˜å‚¨
- [x] çŠ¶æ€ç®¡ç†
- [x] æŠ¥å‘Šç”Ÿæˆï¼ˆMarkdown/JSONï¼‰

