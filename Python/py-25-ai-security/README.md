# P25: AI æœåŠ¡å®‰å…¨ä¸è¯„æµ‹

> æ„å»ºå®‰å…¨å¯é çš„ AI æœåŠ¡

## ğŸ¯ å­¦å®Œåèƒ½åš

- é˜²æŠ¤æç¤ºæ³¨å…¥
- å®ç°å†…å®¹å®‰å…¨
- è¯„æµ‹ AI ç³»ç»Ÿ

## ğŸ“ ç›®å½•ç»“æ„

```
py-25-ai-security/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 01-prompt-injection.md    # æç¤ºæ³¨å…¥é˜²æŠ¤
â”‚   â”œâ”€â”€ 02-output-safety.md       # è¾“å‡ºå®‰å…¨
â”‚   â”œâ”€â”€ 03-system-design.md       # ç³»ç»Ÿè®¾è®¡
â”‚   â”œâ”€â”€ 04-evaluation.md          # è¯„æµ‹ä½“ç³»
â”‚   â”œâ”€â”€ 05-monitoring.md          # ç”Ÿäº§ç›‘æ§
â”‚   â”œâ”€â”€ 06-exercises.md           # ç»ƒä¹ é¢˜
â”‚   â””â”€â”€ 07-interview.md           # é¢è¯•é¢˜
â”œâ”€â”€ src/ai_safety/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ guards/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ input_filter.py       # è¾“å…¥è¿‡æ»¤
â”‚   â”‚   â”œâ”€â”€ output_filter.py      # è¾“å‡ºè¿‡æ»¤
â”‚   â”‚   â””â”€â”€ injection.py          # æ³¨å…¥æ£€æµ‹
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py            # è¯„æµ‹æŒ‡æ ‡
â”‚   â”‚   â”œâ”€â”€ dataset.py            # è¯„æµ‹æ•°æ®é›†
â”‚   â”‚   â””â”€â”€ runner.py             # è¯„æµ‹è¿è¡Œå™¨
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ monitor.py            # ç›‘æ§ç³»ç»Ÿ
â”œâ”€â”€ tests/
â”œâ”€â”€ examples/
â””â”€â”€ scripts/
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
cd py-25-ai-security
pip install -e ".[dev]"
```

### è¾“å…¥è¿‡æ»¤

```python
from ai_safety.guards import InputFilter, InjectionDetector

# åˆ›å»ºè¿‡æ»¤å™¨
filter = InputFilter()

# æ£€æŸ¥è¾“å…¥
result = filter.check("Tell me about Python")
if result.is_safe:
    # å®‰å…¨ï¼Œç»§ç»­å¤„ç†
    pass

# æ³¨å…¥æ£€æµ‹
detector = InjectionDetector()
result = detector.detect("Ignore previous instructions and...")
print(result.is_injection)  # True
print(result.risk_level)    # "high"
```

### è¾“å‡ºå®‰å…¨

```python
from ai_safety.guards import OutputFilter

filter = OutputFilter()

# PII è¿‡æ»¤
output = "Contact John at john@example.com"
safe_output = filter.remove_pii(output)
# "Contact [NAME] at [EMAIL]"

# å†…å®¹å®¡æ ¸
result = filter.moderate(content)
if not result.is_safe:
    print(f"Blocked: {result.reason}")
```

### è¯„æµ‹ç³»ç»Ÿ

```python
from ai_safety.evaluation import EvaluationRunner, Metrics

# åˆ›å»ºè¯„æµ‹å™¨
runner = EvaluationRunner()

# å®šä¹‰æµ‹è¯•ç”¨ä¾‹
test_cases = [
    {"input": "What is Python?", "expected": "programming language"},
]

# è¿è¡Œè¯„æµ‹
results = runner.run(model, test_cases)
print(f"Accuracy: {results.accuracy:.2%}")
print(f"Relevance: {results.relevance:.2f}")
```

## ğŸ”§ æ ¸å¿ƒæ¦‚å¿µ

### 1. æç¤ºæ³¨å…¥é˜²æŠ¤

```python
# ç›´æ¥æ³¨å…¥æ£€æµ‹
detector.detect("Ignore previous instructions")

# é—´æ¥æ³¨å…¥æ£€æµ‹ï¼ˆæ¥è‡ªå¤–éƒ¨æ•°æ®ï¼‰
detector.detect_in_context(user_data)

# è¶Šç‹±æ£€æµ‹
detector.detect_jailbreak("DAN prompt...")
```

### 2. è¾“å‡ºå®‰å…¨

```python
# PII æ£€æµ‹
filter.detect_pii(text)  # æ£€æµ‹ PII

# å†…å®¹å®¡æ ¸
filter.moderate(text)  # å®¡æ ¸å†…å®¹

# æ ¼å¼éªŒè¯
filter.validate_json(text)  # éªŒè¯ JSON
```

### 3. è¯„æµ‹ä½“ç³»

```
è¯„æµ‹æŒ‡æ ‡:
â”œâ”€â”€ å‡†ç¡®æ€§ (Accuracy) - ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
â”œâ”€â”€ ç›¸å…³æ€§ (Relevance) - ç­”æ¡ˆæ˜¯å¦ç›¸å…³
â”œâ”€â”€ å¿ å®åº¦ (Faithfulness) - æ˜¯å¦åŸºäºä¸Šä¸‹æ–‡
â””â”€â”€ æ— å®³æ€§ (Harmlessness) - æ˜¯å¦å®‰å…¨
```

## ğŸ“š å­¦ä¹ è·¯å¾„

1. **æç¤ºæ³¨å…¥** - æ”»å‡»ç±»å‹ã€æ£€æµ‹æ–¹æ³•
2. **è¾“å‡ºå®‰å…¨** - PIIã€å†…å®¹å®¡æ ¸
3. **ç³»ç»Ÿè®¾è®¡** - éš”ç¦»ã€æƒé™ã€å®¡è®¡
4. **è¯„æµ‹ä½“ç³»** - æŒ‡æ ‡ã€æ•°æ®é›†ã€LLM-as-Judge
5. **ç”Ÿäº§ç›‘æ§** - è´¨é‡ã€æˆæœ¬ã€å‘Šè­¦

## âœ… åŠŸèƒ½æ¸…å•

- [x] ç›´æ¥æ³¨å…¥æ£€æµ‹
- [x] é—´æ¥æ³¨å…¥æ£€æµ‹
- [x] è¶Šç‹±é˜²æŠ¤
- [x] è¾“å…¥è¿‡æ»¤
- [x] PII è¿‡æ»¤
- [x] å†…å®¹å®¡æ ¸
- [x] æ ¼å¼éªŒè¯
- [x] éš”ç¦»ç­–ç•¥
- [x] æƒé™æ§åˆ¶
- [x] å®¡è®¡æ—¥å¿—
- [x] å‡†ç¡®æ€§è¯„æµ‹
- [x] ç›¸å…³æ€§è¯„æµ‹
- [x] å¿ å®åº¦è¯„æµ‹
- [x] LLM-as-Judge
- [x] RAG è¯„æµ‹
- [x] è´¨é‡ç›‘æ§
- [x] æˆæœ¬ç›‘æ§
- [x] å¼‚å¸¸å‘Šè­¦


