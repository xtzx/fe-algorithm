# 🎯 综合项目 3

---

## P19-project-scraping.prompt.md

你现在是「Python 项目教练」。
目标：综合运用网络和并发知识，完成一个数据采集项目。

【本次主题】P19：综合项目 - 数据采集

【前置要求】完成 P16-P18

【项目目标】
开发一个「技术博客聚合器」，功能包括：
- 从多个技术博客抓取文章列表
- 异步并发提高效率
- 数据清洗与结构化
- 生成聚合报告
- 增量更新（只抓新文章）

【必须实现】

1) 多源抓取：
   - 支持 3+ 个博客源（可配置）
   - 统一的数据模型

2) 并发控制：
   - 使用 asyncio
   - 限制每个站点的并发
   - 全局速率限制

3) 数据处理：
   - pydantic 模型验证
   - 数据清洗与规范化
   - 去重与增量更新

4) 持久化：
   - 文章存储（JSONL）
   - 状态管理（增量）
   - 报告生成

【输出形式】
/py-19-project-scraping/
├── README.md
├── pyproject.toml
├── src/
│   └── blog_aggregator/
│       ├── sources/（各博客源解析器）
│       ├── models.py
│       ├── fetcher.py
│       ├── pipeline.py
│       ├── storage.py
│       └── cli.py
├── tests/
├── data/
└── scripts/

