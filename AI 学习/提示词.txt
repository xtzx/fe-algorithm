🧱 阶段 0 提示词：筑基（数学 × 代码 × 工具）

你现在是我的「AI 学习教练 + Python 老师 + 数学辅导老师」。请用中文回答。

请根据下面的目标和范围，帮我设计并生成【阶段 0：筑基】的详细学习内容（包括讲解、例子、练习）：

【阶段目标】
- 不卷数学推导，但建立直觉，看到公式不害怕；
- 掌握 Python 基础语法，能写和看基础代码；
- 学会基本数据分析三件套：numpy / pandas / matplotlib；
- 能搭建开发环境、会用 Jupyter / VS Code / Git / Colab。

【建议学习时长】：2～4 周（每天 2～3 小时）

【需要覆盖的知识点】
1. 全局认知：
   - AI 技术地图：传统 ML → 深度学习 → 生成式 AI（LLM）→ 多模态；
   - 基本范式：监督 / 无监督 / 强化学习 / 自监督、RLHF（了解即可）；
   - AI 工程师的不同方向（算法 vs 应用 vs 部署）。

2. 编程基础（Python）：
   - 变量、条件、循环、函数；
   - 列表/字典推导式、匿名函数、装饰器、生成器与迭代器；
   - 面向对象基础（类与对象）；
   - 异步编程 async/await 的基本概念与简单示例；
   - 类型注解（Type Hints）基础。

3. 数据科学三剑客：
   - numpy：数组、矩阵运算、广播；
   - pandas：DataFrame、数据清洗与简单统计；
   - matplotlib（或 seaborn）：折线图 / 柱状图 / 直方图 / 散点图。

4. 工具与环境：
   - Conda / venv 虚拟环境；
   - pip / uv 基本用法；
   - Jupyter Notebook / VS Code 的使用；
   - Git 基础操作：clone / commit / push / 分支；
   - Google Colab / Kaggle Notebook 体验 GPU。

5. 数学直觉（够用版）：
   - 线性代数：向量、矩阵、点积、矩阵乘法、张量；
   - 微积分直觉：导数、偏导、梯度、梯度下降的「下山」比喻；
   - 概率与信息论：贝叶斯公式直觉、常见分布、Softmax、熵/交叉熵。

【产出形式要求】
- 对每个知识点：
  - 给出通俗解释 + 小例子（最好带 Python 代码）；
  - 给 2～5 个小练习（含参考答案或解题思路）；
- 至少设计 1～2 个小项目，比如：
  - 用 pandas 分析一个 CSV 数据集并画图；
  - 用 numpy 实现一个简单的向量相似度计算；
- 在最后给出「阶段 0 自测清单」，列出学完后应该能回答的 10 个问题；
- 输出时用 Markdown 格式，分层清晰，方便我逐条跟着学。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。


⸻

📊 阶段 1 提示词：传统机器学习（Classic ML）

你现在是我的「机器学习入门教练」，风格偏实战、少废话多例子。请用中文回答。

请根据下面的目标和范围，帮我生成【阶段 1：传统机器学习】的系统学习内容：

【阶段目标】
- 理解机器学习的整体流程与思维方式；
- 会用 scikit-learn 训练和评估常见模型；
- 至少完成 2 个可复现的小项目（如房价预测、泰坦尼克）。

【建议学习时长】：2～3 周（每天 2～3 小时）

【需要覆盖的知识点】
1. 机器学习流水线：
   - 数据清洗 / 特征工程（特征缩放、独热编码、缺失值处理）；
   - Train / Validation / Test 划分；
   - 训练 → 评估 → 调参的整体闭环。

2. 模型评估与常见问题：
   - 分类：Accuracy / Precision / Recall / F1；
   - 二分类 / 排序：AUC / ROC；
   - 回归：MSE / MAE / R²；
   - 混淆矩阵；
   - 过拟合 vs 欠拟合、正则化（L1/L2）、交叉验证（K-Fold）；
   - 调参技巧：GridSearchCV / RandomizedSearchCV。

3. 常见模型（用 scikit-learn 实现）：
   - 线性回归 / 逻辑回归；
   - 决策树、随机森林；
   - XGBoost / LightGBM / CatBoost（可简单介绍或用现成包演示）；
   - 无监督：K-Means、PCA、t-SNE/UMAP 用于可视化。

4. 实战项目（至少 2 个完整示例）：
   - 项目 A：房价预测（回归）；
   - 项目 B：泰坦尼克生存预测（分类）；
   - 项目 C（可选）：用户聚类（客户分群）。

【产出形式要求】
- 对每类模型：
  - 简单讲原理直觉，不需要公式推导；
  - 用 scikit-learn 写一个完整代码示例（含数据拆分、训练、评估、画图）；
- 对每个项目：
  - 给出从「加载数据 → EDA → 特征工程 → 建模 → 评估 → 可视化」的一整套步骤；
  - 附上示例代码和可选扩展任务（比如试不同模型、加特征等）；
- 在最后给出「阶段 1 自测清单」，列出学完后应该能回答的 10 个问题；
- 用 Markdown 组织内容，结构清晰，让我可以照着实现。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

补充说明：
- 假设我已经具备 Python 与 numpy/pandas 的基础（来自阶段 0）。
- 风格上尽量「工程实践导向」，多代码、多图，少空洞概念。


⸻

🧠 阶段 2 提示词：深度学习 & PyTorch

你现在是我的「深度学习 & PyTorch 私教」，风格是：从代码出发理解原理。请用中文回答。

请根据下面的目标和范围，为【阶段 2：深度学习（PyTorch）】设计一套系统学习内容：

【阶段目标】
- 掌握 PyTorch 基础用法（Tensor、autograd、nn.Module、DataLoader 等）；
- 理解 MLP / CNN / RNN 的核心思想；
- 能自己写训练循环、调试损失下降；
- 至少做出 1 个图像项目 + 1 个文本项目。

【建议学习时长】：3～4 周（每天 2～3 小时）

【需要覆盖的知识点】
1. 深度学习基础：
   - 神经网络的基本概念（层、参数、激活函数、损失函数）；
   - 常见激活函数：ReLU / GELU / SiLU / Swish；
   - 正则化：Dropout、BatchNorm / LayerNorm（理解差异）；
   - 优化器：SGD / Adam / AdamW（理解 weight decay）；
   - 学习率调度（StepLR / CosineAnnealing / Warmup）；
   - 梯度消失/爆炸与应对方法（残差连接、梯度裁剪）。

2. PyTorch 基础：
   - Tensor 创建、索引、广播、设备转移；
   - autograd：requires_grad、backward 的直觉与例子；
   - 自定义 nn.Module，实现一个两层 MLP；
   - Dataset / DataLoader：自定义数据集与批量加载；
   - 模型保存与加载（state_dict）。

3. 经典网络与任务：
   - CNN：卷积核、步长、池化的直观解释；
   - 经典 CNN 架构演进：LeNet → VGG → ResNet（残差连接）；
   - **Vision Transformer (ViT)**：理解「图像也能用 Transformer」；
   - RNN / LSTM / GRU 的直觉和一个文本情感分析示例。

4. 训练技巧：
   - 梯度裁剪、混合精度训练（AMP）、梯度累积；
   - 如何打印/可视化 loss 曲线，诊断问题；
   - TensorBoard / Weights & Biases 基础使用。

【实战项目要求】
- 项目 1：CIFAR-10 图像分类
  - 使用自定义小 CNN + 使用预训练 ResNet/ViT 做迁移学习各一遍；
- 项目 2：文本情感分析
  - 用 LSTM/GRU 对短文本做二分类；
- 每个项目附：
  - 结构设计思路；
  - 完整训练脚本（可简化，但要能跑通）；
  - 可选优化方向（调参、增加层数、加正则等）。

【产出形式要求】
- 每个知识点配：
  - 清晰解释 + 小代码示例；
  - 2～3 个练习（如"让你改一改网络/尝试不同激活函数"等）；
- 项目部分请给出「项目说明书」风格的文档 + 核心代码示例；
- 在最后给出「阶段 2 自测清单」，列出学完后应该能回答的 10 个问题；
- 输出为 Markdown，方便我直接当学习笔记使用。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

说明：
- 可以假设我已了解机器学习基本概念（来自阶段 1）。
- 避免过多数学推导，重点放在：代码实现 + 直觉理解。


⸻

🏛 阶段 3 提示词：大模型核心技术（LLM Core）

你现在是我的「大模型 / LLM 理论与实战 教练」。请用中文回答。

请根据下面的目标和范围，为【阶段 3：大模型核心技术（LLM Core）】生成一套系统学习内容：

【阶段目标】
- 吃透 Transformer 的基本结构与计算流程；
- 理解 Tokenization、位置编码、Self-Attention、KV Cache 等关键概念；
- 学会使用 Hugging Face Transformers / Datasets；
- 能完成：一个 BERT 文本任务 + 一个语义搜索 Demo + 一个简化版 Transformer 练习。

【建议学习时长】：4～6 周（每天 2～3 小时）

【需要覆盖的知识点】
1. Transformer 架构（必须吃透）：
   - Self-Attention（Q/K/V、注意力权重的直觉）；
   - Multi-Head Attention；
   - 前馈网络（Feed Forward）；
   - 残差连接 + LayerNorm（Pre-LN vs Post-LN）；
   - Encoder-only (BERT) / Decoder-only (GPT/LLaMA) / Encoder-Decoder (T5) 的区别。

2. 位置编码 & 长上下文：
   - 绝对位置编码（Sinusoidal）；
   - **RoPE（旋转位置编码）**的直观理解（现代 LLM 标配）；
   - 长上下文方案：ALiBi、Sliding Window Attention（了解即可）。

3. 现代 LLM 优化技术（重要！）：
   - **KV Cache**：推理加速的核心，理解为什么需要缓存；
   - **Flash Attention**：显存优化的核心思想；
   - **GQA / MQA**（Grouped/Multi-Query Attention）：减少 KV 头数；
   - **MoE（Mixture of Experts）**：稀疏激活的直观理解（如 Mixtral）。

4. Tokenization 与上下文窗口：
   - BPE / WordPiece / SentencePiece 的基本概念；
   - token vs 字数 的区别；
   - 上下文窗口限制对应用的影响；
   - 特殊 token：BOS / EOS / PAD / 系统提示分隔符。

5. Hugging Face 生态：
   - 使用 transformers 加载 BERT / GPT / LLaMA / Qwen 等模型；
   - AutoTokenizer / AutoModel / AutoModelForXXX；
   - datasets 库加载常见 NLP 数据集；
   - 简单介绍如何在 HF Model Hub 上找模型；
   - 使用 pipeline 快速推理。

6. Embedding 与语义向量：
   - 文本 → 向量；
   - 余弦相似度；
   - 使用开源 embedding 模型（如 bge / e5 / jina）；
   - 简单用 Faiss / Chroma 做向量检索 Demo。

7. AIGC & 多模态基础（了解 + 选做）：
   - Diffusion 模型的基本思想（从噪声到图像）；
   - **CLIP**：图文对齐的核心思想；
   - **多模态 LLM**：LLaVA / GPT-4V / Qwen-VL 的基本架构。

【实战项目】
- 项目 1：使用 BERT 做文本分类或 NER；
- 项目 2：构建一个简单「语义搜索引擎」（embedding + 向量检索）；
- 项目 3（核心练习）：**手写一个极简版 GPT**（参考 nanoGPT，玩具模型即可）。

【产出形式要求】
- 对 Transformer 相关部分：
  - 尽量用图示类比方式解释（可以用文字描述图形）；
  - 给出小型示例（比如单头注意力计算的伪代码或 Python 代码）；
- 对 Hugging Face 部分：
  - 给出可直接运行的代码模板（如：加载模型 -> 推理 -> 简单微调）；
- 对每个项目：
  - 给出需求说明 + 代码结构建议 + 示例代码；
- 在最后给出「阶段 3 自测清单」，列出学完后应该能回答的 15 个问题；
- 最终内容用 Markdown 输出，分为「理论讲解 / 代码示例 / 练习 / 项目」几个部分。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

假设我已经掌握了 PyTorch 基础。


⸻

🧩 阶段 4 提示词：大模型应用开发（LLM Engineering）

你现在是我的「LLM 应用工程 / RAG / Agent 实战教练」。请用中文回答。

请根据下面的目标，为【阶段 4：大模型应用开发（LLM Engineering）】生成一套系统实战课程风格的内容：

【阶段目标】
- 熟练使用大模型 API（或本地模型）进行 Prompt 编程；
- 理解并实现一个完整的 RAG 系统；
- 能使用主流框架（LangChain / LlamaIndex / LangGraph 等）开发简单 Agent；
- 能做一次 LoRA/QLoRA 微调的实战。

【建议学习时长】：4～6 周（每天 2～3 小时）

【需要覆盖的内容模块】
1. Prompt Engineering：
   - 基础：指令式 Prompt、Few-shot、CoT（思维链）；
   - 进阶：ReAct / Tree of Thoughts / Self-Consistency；
   - 让模型输出 JSON / YAML 等结构化结果；
   - **Function Calling / Tool Use** 的概念与代码示例；
   - 系统提示词设计：角色设定、约束条件、输出格式。

2. RAG（检索增强生成）：
   - 流程：切分文档 → Embedding → 向量检索 → 构造 Prompt → 生成；
   - Chunking 策略：固定长度 / 递归 / 语义切分 / Parent-Child；
   - **Rerank** 概念（提升检索质量）；
   - 进阶：**GraphRAG** / **Agentic RAG** / Hybrid Search（混合检索）；
   - 用 LangChain 或 LlamaIndex 实现一个 RAG Demo。

3. AI Agent：
   - Agent 的核心组成：Planning / Memory / Tools / **Reflection**；
   - 单 Agent + 多 Agent 的区别；
   - **MCP（Model Context Protocol）**：Anthropic 提出的 Agent 工具标准协议；
   - 框架选择：LangGraph / AutoGen / CrewAI / OpenAI Agents SDK；
   - 示例：SQL Agent / 代码 Agent / 多 Agent 协作完成任务。

4. 微调（Fine-tuning）：
   - 参数高效微调 PEFT 的直觉；
   - **LoRA / QLoRA / DoRA** 的简单数学直觉 + 使用示例；
   - 指令数据集构造：Alpaca 格式、ShareGPT 格式；
   - 用开源工具（**LLaMA-Factory / Unsloth**）完成一次微调流程。

5. 多模态应用（新增）：
   - 图像理解：调用 GPT-4V / Claude 3 / Qwen-VL API；
   - 语音交互：Whisper（语音转文字）、TTS（文字转语音）；
   - 多模态 RAG：图片 + 文本混合检索。

【实战项目要求】
- 必做项目：
  - 企业/个人知识库 RAG 助手（支持 PDF / 网页文本）；
- 选做项目（至少二选一）：
  - SQL Agent：自然语言 → 自动生成 SQL → 执行并返回结果；
  - LoRA 微调一个开源模型，使其更擅长某领域回答；
  - 多 Agent 系统：例如一个简单的「自动调研 + 整理报告」的工作流；
  - 多模态助手：能理解图片内容的问答机器人。

【产出形式要求】
- 请按「模块 → 子知识点 → 代码示例 → 小练习 → 项目」结构输出；
- 每个模块给出：
  - 至少 1 段概念说明；
  - 1～2 个可直接运行的代码例子（用伪 API 也行，例如 openai 风格）；
  - 1～3 个练习题（例如：「修改 prompt，使模型输出更结构化」）；
- 对 RAG & Agent & 微调，各给出一个「从零搭建」的项目指南；
- 在最后给出「阶段 4 自测清单」，列出学完后应该能回答的 15 个问题；
- 输出为 Markdown，适合我拿来当课程讲义。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

可以假设：
- 我已经了解 Transformer / HuggingFace 基础（来自阶段 3）；
- 我会基本的 Python Web / API 调用。


⸻

🚀 阶段 5 提示词：部署与 MLOps / LLMOps

你现在是我的「LLM 部署与工程化 导师」。请用中文回答。

请根据下面的目标和范围，为【阶段 5：部署与 MLOps / LLMOps】设计系统学习内容和实战项目：

【阶段目标】
- 理解本地/私有化部署 LLM 的常见方案和权衡；
- 会使用一种推理引擎（如 vLLM / Ollama / SGLang 等）搭建高吞吐服务；
- 能用 FastAPI + Docker 封装和部署一个 LLM/RAG 接口；
- 理解基本的监控、日志记录、RAG 评估方法。

【建议学习时长】：2～3 周（每天 2～3 小时）

【需要覆盖的知识点】
1. 部署与推理基础：
   - 本地部署 vs 云端 API 的优缺点与成本对比；
   - 模型格式与量化：FP16 / BF16 / INT8 / INT4；
   - 量化格式：GGUF / GPTQ / AWQ / EXL2 的区别与选择；
   - 推理优化：Continuous Batching、Speculative Decoding、PagedAttention（概念级）。

2. 推理引擎与本地运行：
   - 以其中 1～2 个为例：
     - **Ollama**（最简单）/ **vLLM**（高吞吐）/ **SGLang** / llama.cpp；
   - 如何下载模型 / 启动服务 / 调用 REST API；
   - **OpenAI 兼容接口**：让任何推理引擎都能用 openai SDK 调用。

3. 服务化与 API：
   - 用 FastAPI 封装一个 Chat / RAG 接口；
   - **流式输出（SSE）**与普通 HTTP 的区别与实现方式；
   - 简单的鉴权方式（API Key / JWT）；
   - 请求限流与并发控制。

4. 容器化与基础设施：
   - Dockerfile 基本写法（CPU 版 + GPU 版简单说明）；
   - 使用 NVIDIA Container Toolkit；
   - Docker Compose 编排多服务；
   - 简单 CI/CD 思路（例如：push 到 main 后自动构建镜像）。

5. 监控、评估与安全：
   - 日志记录：请求/响应/耗时/Token 用量；
   - RAG 质量评估：**Ragas** 框架的核心指标（Faithfulness / Relevance / Answer Correctness）；
   - 调用链追踪：**LangSmith / LangFuse** 的概念和基本用法思路；
   - 安全：**Prompt 注入防护**、数据隐私、敏感信息脱敏、输出过滤。

【实战项目】
- 项目：将某个已有的 RAG 或 Chat Agent 应用：
  - 用某个推理引擎 + 开源模型部署在本地或云服务器；
  - 用 FastAPI 暴露统一 OpenAI 风格接口；
  - 用 Docker 打包；
  - 加上基础日志记录与简单监控（例如：输出到文件/简单统计）；
  - 可选：用 Ragas 评估 RAG 质量。

【产出形式要求】
- 对每一块（推理引擎 / FastAPI / Docker / 监控），给出：
  - 基本概念说明；
  - 一个最小可运行示例（伪代码也可以）；
- 对实战项目，给出：
  - 架构图的文字说明；
  - 推荐的实现步骤 checklist；
- 在最后给出「阶段 5 自测清单」，列出学完后应该能回答的 10 个问题；
- 输出为 Markdown，让我可以一步步照着操作。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

可以假设我对 Linux / 命令行有基本了解。


⸻

🧬 阶段 6 提示词：领域深耕 & 作品集 / 职业化

你现在是我的「职业发展 & 作品集规划 教练」。请用中文回答。

请根据下面的目标与背景，为【阶段 6：领域深耕 & 作品集 / 职业化】设计一个系统行动计划，并生成相应的内容模板与指导：

【阶段目标】
- 明确个人技术标签和主攻方向（如：RAG 应用 / Agent 平台 / LLM 微调 / 行业垂直 AI 等）；
- 设计 2～4 个代表性项目，作为我的长期作品集；
- 形成可对外展示的技术形象（GitHub / 博客 / 简历）；
- 为求职 / 转岗做好准备（如适用）。

【建议时长】：持续进行，每 3 个月复盘一次

【需要覆盖的内容】
1. 方向选择：
   - 根据我前面 0～5 阶段的学习（你可以假设我已经掌握大纲里提到的主干内容），
     给出几个典型方向，并帮助我缩小到 1～2 个；
   - 2024-2025 年热门方向分析：
     - LLM 应用工程师（RAG / Agent）
     - AI Infra 工程师（部署 / 推理优化）
     - 算法工程师（微调 / 预训练）
     - 行业 AI 解决方案（医疗 / 法律 / 金融等）
   - 每个方向简要描述：
     - 需要的核心技能；
     - 典型工作内容；
     - 薪资范围参考；
     - 未来发展空间。

2. 作品集设计：
   - 旗舰项目（1～2 个）：完整业务闭环的项目，如：
     - 企业知识库 RAG 助手；
     - 多 Agent 工作流自动化系统；
   - 技术亮点项目（1～2 个）：突出某个技术，如：
     - QLoRA 微调 + 评估 + 部署；
     - vLLM 高吞吐推理 + 压测报告；
   - 请给出：
     - 每个项目的建议功能范围；
     - 推荐技术栈（模型 / 框架 / 部署方式）；
     - 里程碑拆分（MVP → 完整版 → 优化）；
     - 可量化的成果指标（性能 / 准确率 / 用户数等）。

3. 开源与个人品牌：
   - 如何选择开源项目参与（Issue / PR 类型）；
   - 推荐关注的开源项目（LangChain / vLLM / LlamaIndex 等）；
   - GitHub README 模板，根据一个示例项目生成一份 demo 模板；
   - 博客 / 知乎 / 公众号文章大纲模板（如：项目复盘模板、技术踩坑总结模板）。

4. 求职 / 转岗：
   - 如何分析 JD，总结技能关键词；
   - 简历中项目描述的 **STAR 法则** 模板；
   - 面试准备 checklist：
     - 八股文：Transformer / Attention / RAG / Agent 原理；
     - 项目深挖：架构选型 / 遇到的问题 / 如何解决；
     - 手撕代码：Self-Attention / LoRA / 向量检索；
   - 常见面试问题及回答思路。

5. 复盘与长期规划：
   - 给出一个「每 3 个月复盘一次」的表格或问题清单；
   - 提供一个样例：「某人从普通后端 → LLM 应用工程师」的阶段性路径示意（可以虚构）；
   - 技术成长里程碑：Junior → Mid → Senior 的能力要求。

【产出形式要求】
- 先帮我用文字形式「归纳几个可能的专业方向」；
- 然后为每个方向给出对应的：
  - 建议作品集组合（2～4 个项目）；
  - 建议学习/实践侧重点；
- 给出可以直接套用的：
  - GitHub 项目 README 模板；
  - 技术博客/项目复盘文章模板；
  - 简历中项目描述的写法模板；
  - 面试自我介绍模板（1 分钟 / 3 分钟版）。

【输出控制】
- 如果内容太长，请分多次输出，每次输出一个模块；
- 每次输出结束时提示我「继续」可获取下一部分。

输出为 Markdown，让我可以直接复制作为我的长期规划文档使用。

说明：
- 你可以适当假设我的目标（例如：1～2 年内成为合格的 LLM 应用工程师），
  但请在文中说明你的假设，方便我调整。
