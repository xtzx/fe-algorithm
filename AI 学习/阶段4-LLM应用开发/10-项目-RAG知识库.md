# ğŸ“š é¡¹ç›®ï¼šä¼ä¸šçŸ¥è¯†åº“ RAG åŠ©æ‰‹

> æ„å»ºä¸€ä¸ªæ”¯æŒ PDF/ç½‘é¡µçš„çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

---

## é¡¹ç›®æ¦‚è¿°

### åŠŸèƒ½éœ€æ±‚

```
1. æ–‡æ¡£ç®¡ç†
   - æ”¯æŒä¸Šä¼  PDFã€TXTã€Markdown æ–‡ä»¶
   - æ”¯æŒç½‘é¡µé“¾æ¥æŠ“å–
   - æ–‡æ¡£åˆ—è¡¨å’Œåˆ é™¤

2. æ™ºèƒ½é—®ç­”
   - åŸºäºçŸ¥è¯†åº“å›ç­”é—®é¢˜
   - æ˜¾ç¤ºå¼•ç”¨æ¥æº
   - æ”¯æŒå¤šè½®å¯¹è¯

3. ç®¡ç†ç•Œé¢
   - æ–‡æ¡£ç®¡ç†
   - å¯¹è¯å†å²
   - ç³»ç»Ÿé…ç½®
```

### æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å‰ç«¯ (Streamlit)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  æ–‡æ¡£ä¸Šä¼     â”‚  â”‚   å¯¹è¯ç•Œé¢   â”‚  â”‚   ç®¡ç†ç•Œé¢   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        åç«¯ (FastAPI)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  æ–‡æ¡£å¤„ç†    â”‚  â”‚  RAG Pipeline â”‚  â”‚  API æœåŠ¡   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        å­˜å‚¨å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚   ChromaDB   â”‚  â”‚   SQLite    â”‚  â”‚   æ–‡ä»¶å­˜å‚¨   â”‚    â”‚
â”‚   â”‚  (å‘é‡å­˜å‚¨)  â”‚  â”‚  (å…ƒæ•°æ®)   â”‚  â”‚   (åŸå§‹æ–‡æ¡£) â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å®Œæ•´ä»£ç 

### é¡¹ç›®ç»“æ„

```
rag_knowledge_base/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # é…ç½®
â”‚   â”œâ”€â”€ document_loader.py # æ–‡æ¡£åŠ è½½
â”‚   â”œâ”€â”€ rag_engine.py      # RAG å¼•æ“
â”‚   â”œâ”€â”€ api.py             # FastAPI æœåŠ¡
â”‚   â””â”€â”€ database.py        # æ•°æ®åº“æ“ä½œ
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py             # Streamlit å‰ç«¯
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/           # ä¸Šä¼ çš„æ–‡ä»¶
â”‚   â””â”€â”€ chroma_db/         # å‘é‡æ•°æ®åº“
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.py
```

### requirements.txt

```
openai>=1.0.0
langchain>=0.1.0
langchain-openai>=0.0.5
langchain-community>=0.0.10
chromadb>=0.4.0
sentence-transformers>=2.2.0
pypdf>=3.0.0
python-docx>=0.8.11
beautifulsoup4>=4.12.0
requests>=2.31.0
fastapi>=0.100.0
uvicorn>=0.23.0
streamlit>=1.28.0
python-multipart>=0.0.6
python-dotenv>=1.0.0
```

### config.py

```python
"""é…ç½®æ–‡ä»¶"""
from pydantic_settings import BaseSettings
from pathlib import Path

class Settings(BaseSettings):
    # OpenAI
    openai_api_key: str = ""
    openai_model: str = "gpt-4o-mini"
    embedding_model: str = "text-embedding-3-small"

    # è·¯å¾„
    base_dir: Path = Path(__file__).parent.parent
    upload_dir: Path = base_dir / "data" / "uploads"
    chroma_dir: Path = base_dir / "data" / "chroma_db"
    db_path: Path = base_dir / "data" / "metadata.db"

    # RAG é…ç½®
    chunk_size: int = 500
    chunk_overlap: int = 50
    top_k: int = 5

    class Config:
        env_file = ".env"

settings = Settings()

# ç¡®ä¿ç›®å½•å­˜åœ¨
settings.upload_dir.mkdir(parents=True, exist_ok=True)
settings.chroma_dir.mkdir(parents=True, exist_ok=True)
```

### document_loader.py

```python
"""æ–‡æ¡£åŠ è½½å™¨"""
from pathlib import Path
from typing import List, Dict
import requests
from bs4 import BeautifulSoup

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredMarkdownLoader
)
from langchain.schema import Document

from app.config import settings

class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å’Œå¤„ç†"""

    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=settings.chunk_size,
            chunk_overlap=settings.chunk_overlap,
            separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
        )

    def load_file(self, file_path: str) -> List[Document]:
        """åŠ è½½æ–‡ä»¶"""
        path = Path(file_path)

        if path.suffix.lower() == ".pdf":
            loader = PyPDFLoader(str(path))
        elif path.suffix.lower() == ".txt":
            loader = TextLoader(str(path), encoding="utf-8")
        elif path.suffix.lower() in [".md", ".markdown"]:
            loader = UnstructuredMarkdownLoader(str(path))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {path.suffix}")

        documents = loader.load()

        # æ·»åŠ å…ƒæ•°æ®
        for doc in documents:
            doc.metadata["source"] = path.name
            doc.metadata["file_path"] = str(path)

        # åˆ‡åˆ†
        chunks = self.text_splitter.split_documents(documents)

        return chunks

    def load_url(self, url: str) -> List[Document]:
        """åŠ è½½ç½‘é¡µ"""
        response = requests.get(url, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")

        # ç§»é™¤è„šæœ¬å’Œæ ·å¼
        for script in soup(["script", "style"]):
            script.decompose()

        # è·å–æ–‡æœ¬
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        text = "\n".join(line for line in lines if line)

        # åˆ›å»ºæ–‡æ¡£
        doc = Document(
            page_content=text,
            metadata={"source": url, "type": "webpage"}
        )

        # åˆ‡åˆ†
        chunks = self.text_splitter.split_documents([doc])

        return chunks

    def process_documents(self, documents: List[Document]) -> List[Dict]:
        """å¤„ç†æ–‡æ¡£ä¸ºå­—å…¸æ ¼å¼"""
        processed = []
        for i, doc in enumerate(documents):
            processed.append({
                "id": f"{doc.metadata.get('source', 'unknown')}_{i}",
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        return processed
```

### rag_engine.py

```python
"""RAG å¼•æ“"""
from typing import List, Dict, Optional
import chromadb
from chromadb.config import Settings as ChromaSettings

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

from app.config import settings
from app.document_loader import DocumentLoader

class RAGEngine:
    """RAG å¼•æ“"""

    def __init__(self):
        # åˆå§‹åŒ– Embedding
        self.embeddings = OpenAIEmbeddings(
            model=settings.embedding_model,
            openai_api_key=settings.openai_api_key
        )

        # åˆå§‹åŒ– ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path=str(settings.chroma_dir),
            settings=ChromaSettings(anonymized_telemetry=False)
        )

        self.collection = self.chroma_client.get_or_create_collection(
            name="knowledge_base",
            metadata={"hnsw:space": "cosine"}
        )

        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=settings.openai_model,
            temperature=0.3,
            openai_api_key=settings.openai_api_key
        )

        # æ–‡æ¡£åŠ è½½å™¨
        self.loader = DocumentLoader()

    def add_document(self, file_path: str) -> int:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # åŠ è½½æ–‡æ¡£
        chunks = self.loader.load_file(file_path)

        if not chunks:
            return 0

        # ç”Ÿæˆ embedding
        texts = [chunk.page_content for chunk in chunks]
        embeddings = self.embeddings.embed_documents(texts)

        # å­˜å‚¨åˆ° ChromaDB
        ids = [f"{file_path}_{i}" for i in range(len(chunks))]
        metadatas = [chunk.metadata for chunk in chunks]

        self.collection.add(
            ids=ids,
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas
        )

        return len(chunks)

    def add_url(self, url: str) -> int:
        """æ·»åŠ ç½‘é¡µåˆ°çŸ¥è¯†åº“"""
        chunks = self.loader.load_url(url)

        if not chunks:
            return 0

        texts = [chunk.page_content for chunk in chunks]
        embeddings = self.embeddings.embed_documents(texts)

        ids = [f"url_{hash(url)}_{i}" for i in range(len(chunks))]
        metadatas = [chunk.metadata for chunk in chunks]

        self.collection.add(
            ids=ids,
            embeddings=embeddings,
            documents=texts,
            metadatas=metadatas
        )

        return len(chunks)

    def search(self, query: str, top_k: int = None) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        if top_k is None:
            top_k = settings.top_k

        # ç”ŸæˆæŸ¥è¯¢ embedding
        query_embedding = self.embeddings.embed_query(query)

        # æ£€ç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )

        # æ ¼å¼åŒ–ç»“æœ
        formatted = []
        for i in range(len(results["documents"][0])):
            formatted.append({
                "content": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "score": 1 - results["distances"][0][i]  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
            })

        return formatted

    def query(self, question: str, chat_history: List[Dict] = None) -> Dict:
        """RAG é—®ç­”"""
        # æ£€ç´¢
        search_results = self.search(question)

        if not search_results:
            return {
                "answer": "æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ã€‚",
                "sources": []
            }

        # æ„é€ ä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"[æ¥æº: {r['metadata'].get('source', 'æœªçŸ¥')}]\n{r['content']}"
            for r in search_results
        ])

        # æ„é€  prompt
        system_message = """ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. åªä½¿ç”¨å‚è€ƒèµ„æ–™ä¸­çš„ä¿¡æ¯å›ç­”
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´
4. åœ¨é€‚å½“æ—¶å€™å¼•ç”¨æ¥æº"""

        user_message = f"""å‚è€ƒèµ„æ–™ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·å›ç­”ï¼š"""

        messages = [
            SystemMessage(content=system_message),
            HumanMessage(content=user_message)
        ]

        # å¦‚æœæœ‰å†å²å¯¹è¯ï¼ŒåŠ å…¥ä¸Šä¸‹æ–‡
        if chat_history:
            history_text = "\n".join([
                f"ç”¨æˆ·: {h['user']}\nåŠ©æ‰‹: {h['assistant']}"
                for h in chat_history[-3:]  # åªä¿ç•™æœ€è¿‘ 3 è½®
            ])
            messages.insert(1, HumanMessage(content=f"å†å²å¯¹è¯ï¼š\n{history_text}"))

        # ç”Ÿæˆå›ç­”
        response = self.llm.invoke(messages)

        return {
            "answer": response.content,
            "sources": [
                {"source": r["metadata"].get("source", "æœªçŸ¥"), "score": r["score"]}
                for r in search_results
            ]
        }

    def delete_document(self, source: str):
        """åˆ é™¤æ–‡æ¡£"""
        # è·å–æ‰€æœ‰ç›¸å…³çš„ ID
        results = self.collection.get(
            where={"source": source},
            include=["metadatas"]
        )

        if results["ids"]:
            self.collection.delete(ids=results["ids"])
            return len(results["ids"])
        return 0

    def get_stats(self) -> Dict:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡"""
        return {
            "total_chunks": self.collection.count(),
            "sources": self._get_unique_sources()
        }

    def _get_unique_sources(self) -> List[str]:
        """è·å–æ‰€æœ‰æ¥æº"""
        results = self.collection.get(include=["metadatas"])
        sources = set()
        for meta in results["metadatas"]:
            if "source" in meta:
                sources.add(meta["source"])
        return list(sources)


# å•ä¾‹
_engine = None

def get_engine() -> RAGEngine:
    global _engine
    if _engine is None:
        _engine = RAGEngine()
    return _engine
```

### api.py

```python
"""FastAPI æœåŠ¡"""
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import shutil
from pathlib import Path

from app.config import settings
from app.rag_engine import get_engine

app = FastAPI(title="RAG çŸ¥è¯†åº“ API")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ¨¡å‹
class QueryRequest(BaseModel):
    question: str
    chat_history: Optional[List[dict]] = None

class URLRequest(BaseModel):
    url: str

# API ç«¯ç‚¹
@app.get("/")
def root():
    return {"message": "RAG çŸ¥è¯†åº“ API", "version": "1.0"}

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """ä¸Šä¼ æ–‡ä»¶"""
    # ä¿å­˜æ–‡ä»¶
    file_path = settings.upload_dir / file.filename
    with open(file_path, "wb") as f:
        shutil.copyfileobj(file.file, f)

    # æ·»åŠ åˆ°çŸ¥è¯†åº“
    engine = get_engine()
    num_chunks = engine.add_document(str(file_path))

    return {
        "message": f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
        "filename": file.filename,
        "chunks": num_chunks
    }

@app.post("/add_url")
async def add_url(request: URLRequest):
    """æ·»åŠ ç½‘é¡µ"""
    engine = get_engine()
    try:
        num_chunks = engine.add_url(request.url)
        return {"message": "ç½‘é¡µæ·»åŠ æˆåŠŸ", "url": request.url, "chunks": num_chunks}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/query")
async def query(request: QueryRequest):
    """é—®ç­”"""
    engine = get_engine()
    result = engine.query(request.question, request.chat_history)
    return result

@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    engine = get_engine()
    return engine.get_stats()

@app.delete("/document/{source}")
async def delete_document(source: str):
    """åˆ é™¤æ–‡æ¡£"""
    engine = get_engine()
    deleted = engine.delete_document(source)
    return {"message": f"åˆ é™¤äº† {deleted} ä¸ªæ–‡æ¡£å—"}

@app.get("/sources")
async def get_sources():
    """è·å–æ‰€æœ‰æ¥æº"""
    engine = get_engine()
    stats = engine.get_stats()
    return {"sources": stats["sources"]}
```

### frontend/app.py

```python
"""Streamlit å‰ç«¯"""
import streamlit as st
import requests
from pathlib import Path

API_URL = "http://localhost:8000"

st.set_page_config(page_title="çŸ¥è¯†åº“åŠ©æ‰‹", page_icon="ğŸ“š", layout="wide")

# åˆå§‹åŒ– session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“ æ–‡æ¡£ç®¡ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£",
        type=["pdf", "txt", "md"],
        help="æ”¯æŒ PDFã€TXTã€Markdown æ ¼å¼"
    )

    if uploaded_file:
        if st.button("ä¸Šä¼ "):
            files = {"file": (uploaded_file.name, uploaded_file, uploaded_file.type)}
            response = requests.post(f"{API_URL}/upload", files=files)
            if response.status_code == 200:
                result = response.json()
                st.success(f"ä¸Šä¼ æˆåŠŸï¼å¤„ç†äº† {result['chunks']} ä¸ªæ–‡æ¡£å—")
            else:
                st.error("ä¸Šä¼ å¤±è´¥")

    st.divider()

    # ç½‘é¡µé“¾æ¥
    url = st.text_input("æ·»åŠ ç½‘é¡µé“¾æ¥")
    if st.button("æ·»åŠ ç½‘é¡µ"):
        if url:
            response = requests.post(f"{API_URL}/add_url", json={"url": url})
            if response.status_code == 200:
                result = response.json()
                st.success(f"æ·»åŠ æˆåŠŸï¼å¤„ç†äº† {result['chunks']} ä¸ªæ–‡æ¡£å—")
            else:
                st.error("æ·»åŠ å¤±è´¥")

    st.divider()

    # çŸ¥è¯†åº“ç»Ÿè®¡
    st.subheader("ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡")
    try:
        stats = requests.get(f"{API_URL}/stats").json()
        st.write(f"æ–‡æ¡£å—æ•°é‡: {stats['total_chunks']}")
        st.write("æ¥æºåˆ—è¡¨:")
        for source in stats.get("sources", []):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"â€¢ {source[:30]}...")
            with col2:
                if st.button("åˆ é™¤", key=f"del_{source}"):
                    requests.delete(f"{API_URL}/document/{source}")
                    st.rerun()
    except:
        st.write("æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡")

    st.divider()

    if st.button("æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.session_state.chat_history = []
        st.rerun()

# ä¸»ç•Œé¢
st.title("ğŸ“š çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹")
st.caption("åŸºäºæ‚¨çš„æ–‡æ¡£è¿›è¡Œæ™ºèƒ½é—®ç­”")

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "sources" in message:
            with st.expander("æŸ¥çœ‹æ¥æº"):
                for source in message["sources"]:
                    st.write(f"â€¢ {source['source']} (ç›¸å…³åº¦: {source['score']:.2f})")

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # è·å–å›ç­”
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = requests.post(
                f"{API_URL}/query",
                json={
                    "question": prompt,
                    "chat_history": st.session_state.chat_history
                }
            )

            if response.status_code == 200:
                result = response.json()
                st.markdown(result["answer"])

                # æ˜¾ç¤ºæ¥æº
                if result.get("sources"):
                    with st.expander("æŸ¥çœ‹æ¥æº"):
                        for source in result["sources"]:
                            st.write(f"â€¢ {source['source']} (ç›¸å…³åº¦: {source['score']:.2f})")

                # ä¿å­˜åˆ°å†å²
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result["answer"],
                    "sources": result.get("sources", [])
                })

                st.session_state.chat_history.append({
                    "user": prompt,
                    "assistant": result["answer"]
                })
            else:
                st.error("è·å–å›ç­”å¤±è´¥ï¼Œè¯·é‡è¯•")
```

### run.py

```python
"""å¯åŠ¨è„šæœ¬"""
import subprocess
import sys
import time
import threading

def run_backend():
    subprocess.run([sys.executable, "-m", "uvicorn", "app.api:app", "--host", "0.0.0.0", "--port", "8000"])

def run_frontend():
    time.sleep(2)  # ç­‰å¾…åç«¯å¯åŠ¨
    subprocess.run([sys.executable, "-m", "streamlit", "run", "frontend/app.py", "--server.port", "8501"])

if __name__ == "__main__":
    # å¯åŠ¨åç«¯
    backend_thread = threading.Thread(target=run_backend)
    backend_thread.start()

    # å¯åŠ¨å‰ç«¯
    run_frontend()
```

---

## è¿è¡Œæ–¹å¼

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®ç¯å¢ƒå˜é‡
echo "OPENAI_API_KEY=sk-xxx" > .env

# 3. å¯åŠ¨åº”ç”¨
python run.py

# æˆ–åˆ†åˆ«å¯åŠ¨
# åç«¯: uvicorn app.api:app --reload
# å‰ç«¯: streamlit run frontend/app.py
```

---

## æ‰©å±•æ–¹å‘

```
1. æ·»åŠ  Rerank æå‡æ£€ç´¢è´¨é‡
2. æ”¯æŒæ›´å¤šæ–‡æ¡£æ ¼å¼ï¼ˆWordã€Excelï¼‰
3. æ·»åŠ ç”¨æˆ·è®¤è¯
4. æ”¯æŒå¤šçŸ¥è¯†åº“
5. æ·»åŠ æ–‡æ¡£é¢„è§ˆ
6. å®ç°å¼‚æ­¥å¤„ç†å¤§æ–‡ä»¶
```

---

## â¡ï¸ ä¸‹ä¸€æ­¥

ç»§ç»­ [11-é¡¹ç›®-SQL-Agent.md](./11-é¡¹ç›®-SQL-Agent.md)

