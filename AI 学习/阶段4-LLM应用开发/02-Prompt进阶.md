# ğŸ¯ 02 - Prompt Engineering è¿›é˜¶

> é«˜çº§ Prompt æŠ€æœ¯ä¸ç»“æ„åŒ–è¾“å‡º

---

## ReActï¼ˆReasoning + Actingï¼‰

### åŸç†

```
ReAct å°†æ¨ç†ï¼ˆReasoningï¼‰å’Œè¡ŒåŠ¨ï¼ˆActingï¼‰äº¤æ›¿è¿›è¡Œï¼š
1. Thoughtï¼šæ¨¡å‹æ€è€ƒå½“å‰æƒ…å†µ
2. Actionï¼šå†³å®šæ‰§è¡Œä»€ä¹ˆæ“ä½œ
3. Observationï¼šè·å–æ“ä½œç»“æœ
4. é‡å¤ç›´åˆ°å®Œæˆä»»åŠ¡

é€‚ç”¨åœºæ™¯ï¼š
- éœ€è¦å¤–éƒ¨å·¥å…·çš„ä»»åŠ¡
- å¤šæ­¥éª¤å¤æ‚é—®é¢˜
- Agent è®¾è®¡
```

### å®ç°ç¤ºä¾‹

```python
from openai import OpenAI

client = OpenAI()

# æ¨¡æ‹Ÿå·¥å…·
def search(query: str) -> str:
    """æ¨¡æ‹Ÿæœç´¢å·¥å…·"""
    fake_data = {
        "python release date": "Python was first released in 1991",
        "python creator": "Python was created by Guido van Rossum",
        "largest planet": "Jupiter is the largest planet in our solar system"
    }
    for key, value in fake_data.items():
        if key in query.lower():
            return value
    return "No relevant information found."

def calculator(expression: str) -> str:
    """è®¡ç®—å™¨å·¥å…·"""
    try:
        return str(eval(expression))
    except:
        return "Invalid expression"

# ReAct Prompt
react_prompt = """
ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿä½¿ç”¨å·¥å…·çš„åŠ©æ‰‹ã€‚

å¯ç”¨å·¥å…·ï¼š
- search(query): æœç´¢ä¿¡æ¯
- calculator(expression): æ•°å­¦è®¡ç®—

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”é—®é¢˜ï¼š

Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: [å·¥å…·åç§°](å‚æ•°)
Observation: [å·¥å…·è¿”å›ç»“æœï¼Œç”±ç³»ç»Ÿå¡«å……]
... (å¯ä»¥é‡å¤å¤šæ¬¡)
Thought: [æœ€ç»ˆæ€è€ƒ]
Answer: [æœ€ç»ˆç­”æ¡ˆ]

é—®é¢˜ï¼š{question}
"""

def react_agent(question: str, max_iterations: int = 5):
    """ReAct Agent å®ç°"""
    tools = {"search": search, "calculator": calculator}

    prompt = react_prompt.format(question=question)

    for i in range(max_iterations):
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            stop=["Observation:"]
        )

        output = response.choices[0].message.content
        prompt += output

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
        if "Answer:" in output:
            return output.split("Answer:")[-1].strip()

        # è§£æ Action
        if "Action:" in output:
            action_line = [l for l in output.split('\n') if "Action:" in l][-1]
            # è§£æå·¥å…·è°ƒç”¨
            import re
            match = re.search(r'Action:\s*(\w+)\((.*?)\)', action_line)
            if match:
                tool_name, tool_arg = match.groups()
                tool_arg = tool_arg.strip('"\'')

                if tool_name in tools:
                    observation = tools[tool_name](tool_arg)
                    prompt += f"\nObservation: {observation}\n"

    return "Unable to find answer"

# æµ‹è¯•
result = react_agent("Python æ˜¯ä»€ä¹ˆæ—¶å€™å‘å¸ƒçš„ï¼Ÿè·ä»Šå¤šå°‘å¹´äº†ï¼Ÿï¼ˆå‡è®¾ç°åœ¨æ˜¯ 2024 å¹´ï¼‰")
print(result)
```

---

## Tree of Thoughtsï¼ˆæ€ç»´æ ‘ï¼‰

### åŸç†

```
ToT å°†é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªæ€è€ƒè·¯å¾„ï¼Œè¯„ä¼°æ¯æ¡è·¯å¾„çš„å‰æ™¯ï¼Œ
é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„è·¯å¾„ç»§ç»­æ¢ç´¢ã€‚

æ­¥éª¤ï¼š
1. ç”Ÿæˆå¤šä¸ªå€™é€‰æ€è·¯
2. è¯„ä¼°æ¯ä¸ªæ€è·¯çš„è´¨é‡
3. é€‰æ‹©æœ€ä½³æ€è·¯ç»§ç»­
4. å›æº¯æˆ–æ‰©å±•
```

### å®ç°ç¤ºä¾‹

```python
def tree_of_thoughts(problem: str, num_thoughts: int = 3, depth: int = 3):
    """ç®€åŒ–ç‰ˆ Tree of Thoughts"""

    # Step 1: ç”Ÿæˆåˆå§‹æ€è·¯
    generate_prompt = f"""
é—®é¢˜ï¼š{problem}

è¯·ç”Ÿæˆ {num_thoughts} ä¸ªä¸åŒçš„è§£å†³æ€è·¯ï¼ˆåªç»™å‡ºæ€è·¯æ–¹å‘ï¼Œä¸è¦å®Œæ•´è§£ç­”ï¼‰ï¼š
"""

    thoughts_response = chat(generate_prompt)

    # Step 2: è¯„ä¼°æ¯ä¸ªæ€è·¯
    evaluate_prompt = f"""
é—®é¢˜ï¼š{problem}

å€™é€‰æ€è·¯ï¼š
{thoughts_response}

è¯·è¯„ä¼°æ¯ä¸ªæ€è·¯çš„å¯è¡Œæ€§ï¼ˆ1-10 åˆ†ï¼‰ï¼Œå¹¶é€‰æ‹©æœ€ä½³æ€è·¯ã€‚
è¾“å‡ºæ ¼å¼ï¼š
æ€è·¯ Xï¼šè¯„åˆ† Y/10ï¼Œç†ç”±ï¼š...
æœ€ä½³æ€è·¯ï¼šX
"""

    evaluation = chat(evaluate_prompt)

    # Step 3: å±•å¼€æœ€ä½³æ€è·¯
    expand_prompt = f"""
é—®é¢˜ï¼š{problem}

é€‰å®šæ€è·¯ï¼š
{evaluation}

è¯·æ²¿ç€æœ€ä½³æ€è·¯ï¼Œç»§ç»­æ·±å…¥åˆ†æå¹¶ç»™å‡ºå®Œæ•´è§£ç­”ã€‚
"""

    final_answer = chat(expand_prompt)
    return final_answer

# ä½¿ç”¨ç¤ºä¾‹
problem = """
ä¸€å®¶åˆ›ä¸šå…¬å¸æƒ³è¦å¼€å‘ä¸€æ¬¾ AI äº§å“ï¼Œä½†é¢„ç®—æœ‰é™ã€‚
è¯·åˆ†æåº”è¯¥ä¼˜å…ˆè€ƒè™‘å“ªäº›åŠŸèƒ½ï¼Œå¦‚ä½•åˆ†é…èµ„æºã€‚
"""
result = tree_of_thoughts(problem)
print(result)
```

---

## Self-Consistencyï¼ˆè‡ªæ´½æ€§ï¼‰

### åŸç†

```
å¤šæ¬¡é‡‡æ ·ä¸åŒçš„æ¨ç†è·¯å¾„ï¼Œç„¶åå¯¹æœ€ç»ˆç­”æ¡ˆè¿›è¡ŒæŠ•ç¥¨ã€‚
é€šè¿‡é›†æˆå¤šä¸ªæ¨ç†è¿‡ç¨‹æ¥æé«˜å‡†ç¡®æ€§ã€‚

æ­¥éª¤ï¼š
1. åŒä¸€é—®é¢˜å¤šæ¬¡é‡‡æ ·ï¼ˆé«˜æ¸©åº¦ï¼‰
2. æå–æ¯æ¬¡çš„æœ€ç»ˆç­”æ¡ˆ
3. æŠ•ç¥¨é€‰æ‹©æœ€é¢‘ç¹çš„ç­”æ¡ˆ
```

### å®ç°ç¤ºä¾‹

```python
from collections import Counter

def self_consistency(question: str, num_samples: int = 5):
    """Self-Consistency å®ç°"""

    prompt = f"""
{question}

è¯·ä¸€æ­¥ä¸€æ­¥æ€è€ƒï¼Œç„¶åç»™å‡ºç­”æ¡ˆã€‚
åœ¨æœ€åç”¨ "ç­”æ¡ˆï¼šX" çš„æ ¼å¼ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
"""

    answers = []

    for _ in range(num_samples):
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,  # è¾ƒé«˜æ¸©åº¦ä»¥è·å¾—å¤šæ ·æ€§
            max_tokens=500
        )

        output = response.choices[0].message.content

        # æå–ç­”æ¡ˆ
        if "ç­”æ¡ˆï¼š" in output:
            answer = output.split("ç­”æ¡ˆï¼š")[-1].strip().split()[0]
            answers.append(answer)

    # æŠ•ç¥¨
    if answers:
        most_common = Counter(answers).most_common(1)[0]
        return {
            "answer": most_common[0],
            "confidence": most_common[1] / len(answers),
            "all_answers": answers
        }

    return None

# æµ‹è¯•
result = self_consistency(
    "ä¸€ä¸ªæˆ¿é—´é‡Œæœ‰ 3 ä¸ªå¼€å…³ï¼Œåˆ†åˆ«æ§åˆ¶å¦ä¸€ä¸ªæˆ¿é—´çš„ 3 ç›ç¯ã€‚"
    "ä½ åªèƒ½è¿›å…¥æœ‰ç¯çš„æˆ¿é—´ä¸€æ¬¡ã€‚å¦‚ä½•ç¡®å®šæ¯ä¸ªå¼€å…³æ§åˆ¶å“ªç›ç¯ï¼Ÿ"
)
print(result)
```

---

## ç»“æ„åŒ–è¾“å‡º

### JSON è¾“å‡º

```python
json_prompt = """
åˆ†æä»¥ä¸‹äº§å“è¯„è®ºï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚

è¯„è®ºï¼š"{review}"

è¯·è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š
{{
    "sentiment": "positive" | "negative" | "neutral",
    "score": 1-5,
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
    "summary": "ä¸€å¥è¯æ€»ç»“",
    "aspects": {{
        "quality": "æ­£é¢/è´Ÿé¢/æœªæåŠ",
        "price": "æ­£é¢/è´Ÿé¢/æœªæåŠ",
        "service": "æ­£é¢/è´Ÿé¢/æœªæåŠ"
    }}
}}

åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

review = "è¿™ä¸ªäº§å“è´¨é‡å¾ˆå¥½ï¼Œä½†æ˜¯ä»·æ ¼æœ‰ç‚¹è´µã€‚å®¢æœæ€åº¦ä¹Ÿä¸é”™ã€‚"
result = chat(json_prompt.format(review=review))
print(result)

# è§£æ JSON
import json
data = json.loads(result)
print(f"æƒ…æ„Ÿ: {data['sentiment']}, è¯„åˆ†: {data['score']}")
```

### ä½¿ç”¨ Pydantic éªŒè¯

```python
from pydantic import BaseModel, Field
from typing import List, Literal
import json

class ReviewAnalysis(BaseModel):
    sentiment: Literal["positive", "negative", "neutral"]
    score: int = Field(ge=1, le=5)
    keywords: List[str]
    summary: str

def analyze_review_structured(review: str) -> ReviewAnalysis:
    prompt = f"""
åˆ†æä»¥ä¸‹äº§å“è¯„è®ºï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºã€‚

è¯„è®ºï¼š"{review}"

è¾“å‡ºæ ¼å¼ï¼š
{{
    "sentiment": "positive" | "negative" | "neutral",
    "score": 1-5 çš„æ•´æ•°,
    "keywords": ["å…³é”®è¯åˆ—è¡¨"],
    "summary": "ä¸€å¥è¯æ€»ç»“"
}}
"""

    result = chat(prompt)

    # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
    result = result.strip()
    if result.startswith("```"):
        result = result.split("```")[1]
        if result.startswith("json"):
            result = result[4:]

    data = json.loads(result)
    return ReviewAnalysis(**data)

# ä½¿ç”¨
analysis = analyze_review_structured("äº§å“è¶…æ£’ï¼ç‰©ç¾ä»·å»‰ï¼Œä¸‹æ¬¡è¿˜ä¹°ï¼")
print(analysis.model_dump())
```

### OpenAI JSON Mode

```python
# OpenAI åŸç”Ÿ JSON æ¨¡å¼
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "è¾“å‡º JSON æ ¼å¼çš„æ•°æ®"},
        {"role": "user", "content": "åˆ—å‡º 3 ä¸ªç¼–ç¨‹è¯­è¨€åŠå…¶ç‰¹ç‚¹"}
    ],
    response_format={"type": "json_object"}
)

result = json.loads(response.choices[0].message.content)
print(result)
```

### OpenAI Structured Outputs

```python
from pydantic import BaseModel
from openai import OpenAI

client = OpenAI()

class ProgrammingLanguage(BaseModel):
    name: str
    year_created: int
    paradigm: str
    use_cases: list[str]

class LanguageList(BaseModel):
    languages: list[ProgrammingLanguage]

# ä½¿ç”¨ parse æ–¹æ³•è·å–ç»“æ„åŒ–è¾“å‡º
response = client.beta.chat.completions.parse(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": "åˆ—å‡º 3 ä¸ªæµè¡Œçš„ç¼–ç¨‹è¯­è¨€"}
    ],
    response_format=LanguageList
)

result = response.choices[0].message.parsed
for lang in result.languages:
    print(f"{lang.name} ({lang.year_created}): {lang.paradigm}")
```

---

## Function Calling / Tool Use

### åŸç†

```
Function Calling è®©æ¨¡å‹èƒ½å¤Ÿï¼š
1. è¯†åˆ«ç”¨æˆ·è¯·æ±‚éœ€è¦ä»€ä¹ˆå·¥å…·
2. ç”Ÿæˆæ­£ç¡®çš„å‡½æ•°å‚æ•°
3. ï¼ˆç”±å¼€å‘è€…æ‰§è¡Œå‡½æ•°ï¼‰
4. åŸºäºå‡½æ•°ç»“æœç”Ÿæˆå›å¤

è¿™æ˜¯æ„å»º Agent çš„åŸºç¡€èƒ½åŠ›ã€‚
```

### OpenAI Function Calling

```python
import json
from openai import OpenAI

client = OpenAI()

# å®šä¹‰å·¥å…·
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_products",
            "description": "æœç´¢äº§å“ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯"
                    },
                    "category": {
                        "type": "string",
                        "description": "äº§å“ç±»åˆ«"
                    },
                    "max_price": {
                        "type": "number",
                        "description": "æœ€é«˜ä»·æ ¼"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

# æ¨¡æ‹Ÿå·¥å…·å®ç°
def get_weather(city: str, unit: str = "celsius") -> dict:
    # å®é™…åº”è°ƒç”¨å¤©æ°” API
    return {"city": city, "temperature": 22, "condition": "æ™´", "unit": unit}

def search_products(query: str, category: str = None, max_price: float = None) -> list:
    # å®é™…åº”æŸ¥è¯¢æ•°æ®åº“
    return [{"name": f"{query} äº§å“1", "price": 99}, {"name": f"{query} äº§å“2", "price": 199}]

# Function Calling æµç¨‹
def chat_with_tools(user_message: str):
    messages = [{"role": "user", "content": user_message}]

    # Step 1: å‘é€æ¶ˆæ¯ç»™æ¨¡å‹
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        tools=tools,
        tool_choice="auto"  # è®©æ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
    )

    assistant_message = response.choices[0].message

    # Step 2: æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if assistant_message.tool_calls:
        messages.append(assistant_message)

        # Step 3: æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
        for tool_call in assistant_message.tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)

            # æ‰§è¡Œå‡½æ•°
            if function_name == "get_weather":
                result = get_weather(**arguments)
            elif function_name == "search_products":
                result = search_products(**arguments)
            else:
                result = {"error": "Unknown function"}

            # æ·»åŠ å·¥å…·ç»“æœ
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": json.dumps(result, ensure_ascii=False)
            })

        # Step 4: è®©æ¨¡å‹åŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤
        final_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )

        return final_response.choices[0].message.content

    # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›
    return assistant_message.content

# æµ‹è¯•
print(chat_with_tools("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"))
print(chat_with_tools("å¸®æˆ‘æœç´¢ä¸€ä¸‹ä»·æ ¼åœ¨ 200 ä»¥å†…çš„è€³æœº"))
```

### Anthropic Tool Use

```python
import anthropic

client = anthropic.Anthropic()

tools = [
    {
        "name": "get_weather",
        "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
        "input_schema": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°"}
            },
            "required": ["city"]
        }
    }
]

response = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    tools=tools,
    messages=[{"role": "user", "content": "ä¸Šæµ·å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
)

# æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
for block in response.content:
    if block.type == "tool_use":
        print(f"è°ƒç”¨å·¥å…·: {block.name}")
        print(f"å‚æ•°: {block.input}")
```

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹  1ï¼šReAct Agent

```python
# ä»»åŠ¡ï¼šæ‰©å±• ReAct agentï¼Œæ·»åŠ ä»¥ä¸‹å·¥å…·ï¼š
# - weather(city): è·å–å¤©æ°”
# - translate(text, target_lang): ç¿»è¯‘æ–‡æœ¬
# - news(topic): è·å–æ–°é—»
#
# æµ‹è¯•é—®é¢˜ï¼š"åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿå¸®æˆ‘ç¿»è¯‘æˆè‹±æ–‡ã€‚"
```

### ç»ƒä¹  2ï¼šç»“æ„åŒ–è¾“å‡º

```python
# ä»»åŠ¡ï¼šè®¾è®¡ä¸€ä¸ª promptï¼Œå°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–çš„æ—¥ç¨‹å®‰æ’
#
# è¾“å…¥ï¼š"æ˜å¤©ä¸‹åˆ 3 ç‚¹å’Œå¼ æ€»å¼€ä¼šè®¨è®ºé¡¹ç›®è¿›åº¦ï¼Œå¤§æ¦‚ä¸€å°æ—¶"
# è¾“å‡ºæ ¼å¼ï¼š
# {
#     "title": "...",
#     "date": "...",
#     "start_time": "...",
#     "duration_minutes": ...,
#     "participants": [...],
#     "description": "..."
# }
```

### ç»ƒä¹  3ï¼šFunction Calling

```python
# ä»»åŠ¡ï¼šå®ç°ä¸€ä¸ªå¸¦å·¥å…·çš„åŠ©æ‰‹ï¼Œæ”¯æŒï¼š
# - æŸ¥è¯¢ç”¨æˆ·ä½™é¢
# - è½¬è´¦
# - æŸ¥è¯¢äº¤æ˜“è®°å½•
#
# æ³¨æ„å®‰å…¨æ€§ï¼šè½¬è´¦éœ€è¦ç¡®è®¤
```

---

## å°ç»“

```
æœ¬èŠ‚è¦ç‚¹ï¼š
1. ReActï¼šæ¨ç†ä¸è¡ŒåŠ¨äº¤æ›¿ï¼Œé€‚åˆéœ€è¦å·¥å…·çš„ä»»åŠ¡
2. ToTï¼šå¤šè·¯å¾„æ¢ç´¢ï¼Œé€‚åˆå¤æ‚å†³ç­–é—®é¢˜
3. Self-Consistencyï¼šå¤šæ¬¡é‡‡æ ·æŠ•ç¥¨ï¼Œæé«˜å‡†ç¡®æ€§
4. ç»“æ„åŒ–è¾“å‡ºï¼šJSON æ ¼å¼ã€Pydantic éªŒè¯
5. Function Callingï¼šè®©æ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·
```

---

## â¡ï¸ ä¸‹ä¸€æ­¥

ç»§ç»­ [03-RAGåŸºç¡€.md](./03-RAGåŸºç¡€.md)

