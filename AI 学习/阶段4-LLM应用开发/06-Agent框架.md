# ğŸ› ï¸ Agent æ¡†æ¶ä¸ MCP

> LangGraphã€AutoGenã€CrewAI ä¸ MCP åè®®

---

## LangGraph

### æ¦‚è¿°

```
LangGraph æ˜¯ LangChain å›¢é˜Ÿå¼€å‘çš„ Agent ç¼–æ’æ¡†æ¶ï¼š
- åŸºäºå›¾çš„çŠ¶æ€æœºæ¨¡å‹
- æ”¯æŒå¾ªç¯å’Œæ¡ä»¶åˆ†æ”¯
- å†…ç½®æŒä¹…åŒ–å’Œæ£€æŸ¥ç‚¹
- æ”¯æŒäººå·¥å¹²é¢„

æ ¸å¿ƒæ¦‚å¿µï¼š
- Stateï¼šçŠ¶æ€
- Nodeï¼šèŠ‚ç‚¹ï¼ˆå¤„ç†é€»è¾‘ï¼‰
- Edgeï¼šè¾¹ï¼ˆæµè½¬è§„åˆ™ï¼‰
```

### åŸºç¡€ç¤ºä¾‹

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
from operator import add

# å®šä¹‰çŠ¶æ€
class AgentState(TypedDict):
    messages: Annotated[list, add]  # æ¶ˆæ¯åˆ—è¡¨ï¼ˆç´¯åŠ ï¼‰
    next_step: str

# åˆ›å»ºå›¾
workflow = StateGraph(AgentState)

# å®šä¹‰èŠ‚ç‚¹
def agent_node(state: AgentState) -> AgentState:
    """Agent å†³ç­–èŠ‚ç‚¹"""
    messages = state["messages"]

    # è°ƒç”¨ LLM å†³ç­–
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": messages[-1]}]
    )

    result = response.choices[0].message.content

    # åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
    if "éœ€è¦æœç´¢" in result:
        return {"messages": [result], "next_step": "tool"}
    else:
        return {"messages": [result], "next_step": "end"}

def tool_node(state: AgentState) -> AgentState:
    """å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹"""
    # æ‰§è¡Œå·¥å…·
    tool_result = "å·¥å…·æ‰§è¡Œç»“æœ..."
    return {"messages": [tool_result], "next_step": "agent"}

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("agent", agent_node)
workflow.add_node("tool", tool_node)

# è®¾ç½®å…¥å£
workflow.set_entry_point("agent")

# å®šä¹‰è¾¹
def should_continue(state: AgentState) -> str:
    """å†³å®šä¸‹ä¸€æ­¥"""
    if state["next_step"] == "end":
        return END
    return state["next_step"]

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {"tool": "tool", END: END}
)

workflow.add_edge("tool", "agent")  # å·¥å…·æ‰§è¡Œåå›åˆ° agent

# ç¼–è¯‘
app = workflow.compile()

# è¿è¡Œ
result = app.invoke({"messages": ["å¸®æˆ‘æœç´¢ä»Šå¤©çš„æ–°é—»"], "next_step": ""})
print(result)
```

### ReAct Agent with LangGraph

```python
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# å®šä¹‰å·¥å…·
@tool
def search(query: str) -> str:
    """æœç´¢äº’è”ç½‘"""
    return f"æœç´¢ç»“æœ: {query}"

@tool
def calculator(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    return str(eval(expression))

# åˆ›å»º LLM
llm = ChatOpenAI(model="gpt-4o-mini")

# åˆ›å»º ReAct Agent
agent = create_react_agent(llm, [search, calculator])

# è¿è¡Œ
result = agent.invoke({
    "messages": [{"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]
})

for message in result["messages"]:
    print(f"{message.type}: {message.content}")
```

### å¸¦æ£€æŸ¥ç‚¹çš„ Agent

```python
from langgraph.checkpoint.memory import MemorySaver

# åˆ›å»ºæ£€æŸ¥ç‚¹å­˜å‚¨
checkpointer = MemorySaver()

# åˆ›å»ºå¸¦æŒä¹…åŒ–çš„ Agent
agent = create_react_agent(llm, [search, calculator], checkpointer=checkpointer)

# è¿è¡Œï¼ˆå¸¦ thread_id å®ç°å¤šè½®å¯¹è¯ï¼‰
config = {"configurable": {"thread_id": "user-123"}}

result1 = agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«å°æ˜"}]},
    config
)

result2 = agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}]},
    config
)

print(result2["messages"][-1].content)  # åº”è¯¥è®°å¾—å«å°æ˜
```

---

## AutoGen

### æ¦‚è¿°

```
AutoGen æ˜¯å¾®è½¯å¼€å‘çš„å¤š Agent æ¡†æ¶ï¼š
- æ”¯æŒå¤š Agent å¯¹è¯
- å¯é…ç½®çš„å¯¹è¯æ¨¡å¼
- æ”¯æŒäººå·¥å‚ä¸
- ä»£ç æ‰§è¡Œèƒ½åŠ›å¼º

é€‚ç”¨åœºæ™¯ï¼š
- ä»£ç ç”Ÿæˆå’Œè°ƒè¯•
- å¤šè§’è‰²åä½œ
- å¤æ‚ä»»åŠ¡åˆ†è§£
```

### åŒ Agent å¯¹è¯

```python
from autogen import ConversableAgent

# åˆ›å»ºä¸¤ä¸ª Agent
assistant = ConversableAgent(
    name="Assistant",
    system_message="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚",
    llm_config={"model": "gpt-4o-mini"}
)

user_proxy = ConversableAgent(
    name="User",
    human_input_mode="NEVER",  # è‡ªåŠ¨æ¨¡å¼
    code_execution_config=False
)

# å¼€å§‹å¯¹è¯
user_proxy.initiate_chat(
    assistant,
    message="å¸®æˆ‘å†™ä¸€ä¸ª Python å¿«é€Ÿæ’åºå‡½æ•°"
)
```

### ä»£ç æ‰§è¡Œ Agent

```python
from autogen import AssistantAgent, UserProxyAgent
from autogen.coding import LocalCommandLineCodeExecutor

# ä»£ç æ‰§è¡Œå™¨
code_executor = LocalCommandLineCodeExecutor(work_dir="./coding")

# ç”¨æˆ·ä»£ç†ï¼ˆå¯ä»¥æ‰§è¡Œä»£ç ï¼‰
user_proxy = UserProxyAgent(
    name="User",
    human_input_mode="NEVER",
    code_execution_config={"executor": code_executor},
    is_termination_msg=lambda msg: "TERMINATE" in msg.get("content", "")
)

# åŠ©æ‰‹
assistant = AssistantAgent(
    name="Coder",
    system_message="""ä½ æ˜¯ä¸€ä¸ª Python ä¸“å®¶ã€‚
ç¼–å†™ä»£ç æ—¶ï¼š
1. åªè¾“å‡ºä»£ç å—
2. ä»£ç è¦å®Œæ•´å¯è¿è¡Œ
3. å®Œæˆåè¯´ TERMINATE""",
    llm_config={"model": "gpt-4o-mini"}
)

# æ‰§è¡Œä»»åŠ¡
user_proxy.initiate_chat(
    assistant,
    message="åˆ›å»ºä¸€ä¸ªç®€å•çš„ Flask APIï¼Œæœ‰ä¸€ä¸ªè¿”å› 'Hello World' çš„ç«¯ç‚¹"
)
```

### å¤š Agent ç¾¤èŠ

```python
from autogen import GroupChat, GroupChatManager

# åˆ›å»ºå¤šä¸ªä¸“ä¸š Agent
planner = AssistantAgent(
    name="Planner",
    system_message="ä½ æ˜¯é¡¹ç›®è§„åˆ’å¸ˆï¼Œè´Ÿè´£åˆ†è§£ä»»åŠ¡ã€‚",
    llm_config={"model": "gpt-4o-mini"}
)

coder = AssistantAgent(
    name="Coder",
    system_message="ä½ æ˜¯ç¨‹åºå‘˜ï¼Œè´Ÿè´£ç¼–å†™ä»£ç ã€‚",
    llm_config={"model": "gpt-4o-mini"}
)

reviewer = AssistantAgent(
    name="Reviewer",
    system_message="ä½ æ˜¯ä»£ç å®¡æŸ¥å‘˜ï¼Œè´Ÿè´£æ£€æŸ¥ä»£ç è´¨é‡ã€‚",
    llm_config={"model": "gpt-4o-mini"}
)

user = UserProxyAgent(
    name="User",
    human_input_mode="NEVER",
    code_execution_config=False
)

# åˆ›å»ºç¾¤èŠ
groupchat = GroupChat(
    agents=[user, planner, coder, reviewer],
    messages=[],
    max_round=10
)

manager = GroupChatManager(groupchat=groupchat, llm_config={"model": "gpt-4o-mini"})

# å¼€å§‹ç¾¤èŠ
user.initiate_chat(
    manager,
    message="å¼€å‘ä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹ API"
)
```

---

## CrewAI

### æ¦‚è¿°

```
CrewAI ä¸“æ³¨äºå¤š Agent è§’è‰²åä½œï¼š
- åŸºäºè§’è‰²ï¼ˆAgentï¼‰å’Œä»»åŠ¡ï¼ˆTaskï¼‰
- å†…ç½®å·¥ä½œæµç¼–æ’
- æ”¯æŒé¡ºåºå’Œå¹¶è¡Œæ‰§è¡Œ
- ç®€æ´çš„ API
```

### åŸºç¡€ç¤ºä¾‹

```python
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")

# å®šä¹‰ Agent
researcher = Agent(
    role="ç ”ç©¶å‘˜",
    goal="æ”¶é›†å’Œåˆ†æä¿¡æ¯",
    backstory="ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„ç ”ç©¶å‘˜ï¼Œæ“…é•¿æ”¶é›†å’Œæ•´ç†ä¿¡æ¯ã€‚",
    llm=llm,
    verbose=True
)

writer = Agent(
    role="ä½œå®¶",
    goal="æ’°å†™é«˜è´¨é‡çš„å†…å®¹",
    backstory="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šä½œå®¶ï¼Œæ“…é•¿å°†å¤æ‚ä¿¡æ¯è½¬åŒ–ä¸ºæ˜“è¯»çš„æ–‡ç« ã€‚",
    llm=llm,
    verbose=True
)

# å®šä¹‰ä»»åŠ¡
research_task = Task(
    description="ç ”ç©¶äººå·¥æ™ºèƒ½çš„æœ€æ–°å‘å±•è¶‹åŠ¿",
    expected_output="ä¸€ä»½è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š",
    agent=researcher
)

writing_task = Task(
    description="åŸºäºç ”ç©¶æŠ¥å‘Šæ’°å†™ä¸€ç¯‡ç§‘æ™®æ–‡ç« ",
    expected_output="ä¸€ç¯‡ 500 å­—çš„ç§‘æ™®æ–‡ç« ",
    agent=writer
)

# åˆ›å»º Crew
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task],
    process=Process.sequential,  # é¡ºåºæ‰§è¡Œ
    verbose=True
)

# æ‰§è¡Œ
result = crew.kickoff()
print(result)
```

### å¸¦å·¥å…·çš„ Crew

```python
from crewai_tools import SerperDevTool, WebsiteSearchTool

# åˆ›å»ºå·¥å…·
search_tool = SerperDevTool()
web_tool = WebsiteSearchTool()

# é…ç½® Agent ä½¿ç”¨å·¥å…·
researcher = Agent(
    role="ç ”ç©¶å‘˜",
    goal="ä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†æœ€æ–°ä¿¡æ¯",
    tools=[search_tool, web_tool],
    llm=llm
)
```

---

## MCPï¼ˆModel Context Protocolï¼‰

### æ¦‚è¿°

```
MCP æ˜¯ Anthropic æå‡ºçš„ Agent å·¥å…·æ ‡å‡†åè®®ï¼š
- ç»Ÿä¸€çš„å·¥å…·å®šä¹‰æ ¼å¼
- æ ‡å‡†åŒ–çš„å·¥å…·è°ƒç”¨æµç¨‹
- æ”¯æŒå¤šç§å·¥å…·ç±»å‹
- å¯æ‰©å±•æ¶æ„

ç›®æ ‡ï¼šè®© Agent èƒ½å¤Ÿè¿æ¥åˆ°ä»»ä½•æ•°æ®æºå’Œå·¥å…·
```

### MCP æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MCP æ¶æ„                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚   Client    â”‚ â†â”€â”€ MCP Protocol â”€â”€â†’ â”‚   Server    â”‚      â”‚
â”‚   â”‚  (Claude)   â”‚                     â”‚  (å·¥å…·)     â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â”‚   åè®®å†…å®¹ï¼š                                                 â”‚
â”‚   - Resources: æ•°æ®/æ–‡ä»¶è®¿é—®                                 â”‚
â”‚   - Tools: å¯æ‰§è¡Œæ“ä½œ                                        â”‚
â”‚   - Prompts: é¢„å®šä¹‰æç¤ºè¯                                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MCP Server ç¤ºä¾‹

```python
from mcp import Server
from mcp.types import Resource, Tool

# åˆ›å»º MCP Server
server = Server("my-server")

# æ³¨å†Œèµ„æº
@server.resource("file://{path}")
async def read_file(path: str) -> str:
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    with open(path, 'r') as f:
        return f.read()

# æ³¨å†Œå·¥å…·
@server.tool("search")
async def search(query: str) -> str:
    """æœç´¢å·¥å…·"""
    # å®ç°æœç´¢é€»è¾‘
    return f"æœç´¢ {query} çš„ç»“æœ"

@server.tool("execute_sql")
async def execute_sql(query: str, database: str) -> str:
    """æ‰§è¡Œ SQL æŸ¥è¯¢"""
    import sqlite3
    conn = sqlite3.connect(database)
    result = conn.execute(query).fetchall()
    conn.close()
    return str(result)

# è¿è¡ŒæœåŠ¡å™¨
if __name__ == "__main__":
    server.run()
```

### åœ¨ Claude Desktop ä¸­ä½¿ç”¨ MCP

```json
// claude_desktop_config.json
{
  "mcpServers": {
    "my-server": {
      "command": "python",
      "args": ["path/to/my_mcp_server.py"]
    },
    "sqlite": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-sqlite", "path/to/db.sqlite"]
    }
  }
}
```

### å¸¸ç”¨ MCP Servers

```bash
# æ–‡ä»¶ç³»ç»Ÿ
npx @modelcontextprotocol/server-filesystem /path/to/dir

# SQLite æ•°æ®åº“
npx @modelcontextprotocol/server-sqlite database.db

# GitHub
npx @modelcontextprotocol/server-github

# Slack
npx @modelcontextprotocol/server-slack
```

---

## æ¡†æ¶å¯¹æ¯”

| ç‰¹æ€§ | LangGraph | AutoGen | CrewAI |
|------|-----------|---------|--------|
| æ¶æ„ | å›¾çŠ¶æ€æœº | å¯¹è¯é©±åŠ¨ | è§’è‰²ä»»åŠ¡ |
| å¤æ‚åº¦ | ä¸­ | ä½ | ä½ |
| çµæ´»æ€§ | é«˜ | ä¸­ | ä¸­ |
| ä»£ç æ‰§è¡Œ | éœ€æ‰©å±• | å†…ç½® | éœ€æ‰©å±• |
| å¤š Agent | æ”¯æŒ | ä¸“é•¿ | ä¸“é•¿ |
| æŒä¹…åŒ– | å†…ç½® | éœ€æ‰©å±• | éœ€æ‰©å±• |
| é€‚ç”¨åœºæ™¯ | å¤æ‚å·¥ä½œæµ | ç¼–ç¨‹ä»»åŠ¡ | è§’è‰²åä½œ |

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹  1ï¼šLangGraph å·¥ä½œæµ

```python
# ä»»åŠ¡ï¼šä½¿ç”¨ LangGraph å®ç°ä¸€ä¸ªæ–‡æ¡£å¤„ç†å·¥ä½œæµ
# 1. æ–‡æ¡£ä¸Šä¼ 
# 2. å†…å®¹æå–
# 3. æ‘˜è¦ç”Ÿæˆ
# 4. å…³é”®è¯æå–
# 5. å­˜å‚¨
```

### ç»ƒä¹  2ï¼šAutoGen ä»£ç åŠ©æ‰‹

```python
# ä»»åŠ¡ï¼šä½¿ç”¨ AutoGen åˆ›å»ºä¸€ä¸ªä»£ç åŠ©æ‰‹
# - èƒ½å¤Ÿç¼–å†™ä»£ç 
# - èƒ½å¤Ÿæ‰§è¡Œä»£ç 
# - èƒ½å¤Ÿè°ƒè¯•é”™è¯¯
```

### ç»ƒä¹  3ï¼šCrewAI ç ”ç©¶å›¢é˜Ÿ

```python
# ä»»åŠ¡ï¼šä½¿ç”¨ CrewAI åˆ›å»ºä¸€ä¸ªç ”ç©¶å›¢é˜Ÿ
# - ç ”ç©¶å‘˜ï¼šæ”¶é›†ä¿¡æ¯
# - åˆ†æå¸ˆï¼šåˆ†ææ•°æ®
# - æŠ¥å‘Šå‘˜ï¼šæ’°å†™æŠ¥å‘Š
```

---

## å°ç»“

```
æœ¬èŠ‚è¦ç‚¹ï¼š
1. LangGraphï¼šåŸºäºå›¾çš„çŠ¶æ€æœºï¼Œé€‚åˆå¤æ‚å·¥ä½œæµ
2. AutoGenï¼šå¯¹è¯é©±åŠ¨ï¼Œæ“…é•¿ä»£ç ä»»åŠ¡
3. CrewAIï¼šè§’è‰²åä½œï¼Œç®€æ´æ˜“ç”¨
4. MCPï¼šAnthropic çš„å·¥å…·æ ‡å‡†åè®®
```

---

## â¡ï¸ ä¸‹ä¸€æ­¥

ç»§ç»­ [07-å¾®è°ƒåŸºç¡€.md](./07-å¾®è°ƒåŸºç¡€.md)

