# ✅ 15 - 阶段4 自测清单

> 检验 LLM 应用开发能力

---

## 概念理解（15 题）

### Prompt Engineering

```
Q1: Few-shot 和 Zero-shot 的区别是什么？什么时候用哪种？

答案：
- Zero-shot：不提供示例，直接让模型完成任务
- Few-shot：在 prompt 中提供几个示例

使用场景：
- Zero-shot：简单任务、模型已经理解的任务
- Few-shot：特定格式要求、专业领域、复杂分类
```

```
Q2: Chain of Thought（CoT）为什么能提高推理准确性？

答案：
1. 强制模型展示中间步骤，减少跳跃推理
2. 每一步都可以验证，减少累积错误
3. 激活模型更深层的推理能力
4. 类似人类的思考过程
```

```
Q3: Function Calling 的工作流程是什么？

答案：
1. 用户发送消息 + 工具定义
2. 模型判断是否需要调用工具
3. 如需要，返回函数名和参数
4. 开发者执行函数，获取结果
5. 将结果返回给模型
6. 模型基于结果生成最终回答
```

### RAG

```
Q4: RAG 相比直接使用 LLM 有什么优势？

答案：
1. 知识可更新：无需重新训练
2. 减少幻觉：基于真实文档
3. 可追溯：答案有来源
4. 成本低：比微调便宜
5. 隐私：数据不需要发送给模型训练
```

```
Q5: 为什么需要 Rerank？它和 Embedding 检索的区别？

答案：
- Embedding 检索（Bi-Encoder）：
  - Query 和 Doc 分别编码
  - 速度快，适合大规模召回
  - 但不考虑 query-doc 交互

- Rerank（Cross-Encoder）：
  - 同时看 query 和 doc
  - 更精确，但速度慢
  - 适合对召回结果精排

两阶段：先用 Embedding 快速召回，再用 Rerank 精排
```

```
Q6: 什么是 Hybrid Search？为什么要用？

答案：
Hybrid Search = BM25（稀疏检索）+ Embedding（稠密检索）

为什么需要：
- BM25 擅长精确关键词匹配
- Embedding 擅长语义理解
- 结合两者优势

融合方式：
- 线性加权：α * dense + (1-α) * sparse
- RRF：基于排名的融合
```

```
Q7: GraphRAG 相比普通 RAG 的优势是什么？

答案：
1. 捕获实体关系：能理解文档间的关联
2. 多跳推理：可以通过关系链找答案
3. 结构化知识：更好的知识组织
4. 全局视角：能生成摘要和主题分析
```

### Agent

```
Q8: Agent 的四大核心组件是什么？各自的作用？

答案：
1. Planning（规划）：
   - 任务分解、策略选择

2. Memory（记忆）：
   - 短期：当前对话
   - 长期：持久化知识
   - 工作：当前任务状态

3. Tools（工具）：
   - 搜索、计算、API 调用等外部能力

4. Reflection（反思）：
   - 自我评估、错误纠正、改进策略
```

```
Q9: ReAct 模式的工作流程？

答案：
ReAct = Reasoning + Acting

流程：
1. Thought：分析当前情况
2. Action：决定执行什么工具
3. Observation：获取工具结果
4. 重复直到得到答案

示例：
Thought: 用户问天气，需要调用天气 API
Action: weather("北京")
Observation: 北京今天 25°C，晴
Thought: 已有答案
Answer: 北京今天天气晴朗，25°C
```

```
Q10: MCP（Model Context Protocol）是什么？

答案：
MCP 是 Anthropic 提出的 Agent 工具标准协议：

核心概念：
- Resources：数据/文件访问
- Tools：可执行的操作
- Prompts：预定义的提示词

优势：
- 统一的工具定义格式
- 标准化的调用流程
- 可扩展的架构
```

### 微调

```
Q11: 为什么 LoRA 能大幅减少训练参数？

答案：
LoRA 利用低秩分解：
- 原始权重更新 ΔW (d×k)
- 分解为 ΔW = BA
- B: (d×r), A: (r×k)
- r << min(d, k)

例如：d=k=4096, r=8
- 原始：16M 参数
- LoRA：65K 参数（约 0.4%）

原理：权重更新通常是低秩的，不需要全部参数
```

```
Q12: QLoRA 相比 LoRA 的优势？

答案：
QLoRA = 量化 + LoRA

优势：
1. 显存大幅降低（约 4 倍）
2. 可以在消费级 GPU 微调大模型
3. 效果接近全精度 LoRA

关键技术：
- NF4：4-bit 量化
- Double Quantization：量化常数也量化
- Paged Optimizer：分页优化器
```

```
Q13: Alpaca 和 ShareGPT 数据格式的区别？

答案：
Alpaca 格式（单轮）：
{
    "instruction": "任务描述",
    "input": "输入（可选）",
    "output": "输出"
}

ShareGPT 格式（多轮）：
{
    "conversations": [
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "..."},
        ...
    ]
}

使用场景：
- Alpaca：指令微调
- ShareGPT：对话微调
```

### 多模态

```
Q14: 如何使用 GPT-4o 分析图片？

答案：
通过 messages 中包含图片：

content = [
    {"type": "text", "text": "描述这张图片"},
    {
        "type": "image_url",
        "image_url": {
            "url": "data:image/jpeg;base64,{base64_string}"
            # 或直接使用 URL
        }
    }
]

支持的格式：JPEG、PNG、GIF、WebP
```

```
Q15: Whisper 和 TTS 分别是什么？

答案：
Whisper（ASR - 语音识别）：
- 将语音转换为文字
- 支持多语言
- 可以识别时间戳

TTS（Text-to-Speech - 语音合成）：
- 将文字转换为语音
- 支持多种声音
- 可调节语速、语调
```

---

## 编程任务（3 题）

### 任务1：实现 RAG Pipeline

```python
# 任务：实现一个简单的 RAG 系统
# 要求：
# 1. 支持添加文档（切分 + Embedding）
# 2. 支持查询（检索 + 生成）
# 3. 返回答案和来源

class SimpleRAG:
    def add_document(self, text: str, source: str):
        """添加文档"""
        pass

    def query(self, question: str) -> dict:
        """查询，返回 {"answer": ..., "sources": [...]}"""
        pass

# 测试
rag = SimpleRAG()
rag.add_document("Python 是一种编程语言...", "python.txt")
result = rag.query("Python 是什么？")
```

**参考答案见 03-RAG基础.md**

### 任务2：实现 Tool Calling

```python
# 任务：实现一个支持工具调用的对话系统
# 工具：
# - calculator(expression): 计算数学表达式
# - search(query): 搜索信息（模拟）
# - weather(city): 查询天气（模拟）

def chat_with_tools(user_message: str) -> str:
    """支持工具调用的对话"""
    pass

# 测试
print(chat_with_tools("计算 (15 + 27) * 3"))
print(chat_with_tools("北京今天天气怎么样？"))
```

**参考答案见 02-Prompt进阶.md**

### 任务3：LoRA 配置

```python
# 任务：为以下场景选择合适的 LoRA 配置并解释原因

# 场景1：8GB 显存微调 7B 模型
# 场景2：追求最佳效果
# 场景3：快速实验

# 回答格式：
config_1 = {
    "r": ...,
    "lora_alpha": ...,
    "target_modules": [...],
    "load_in_4bit": ...,
    "reason": "..."
}
```

**参考答案：**

```python
# 场景1：8GB 显存
config_1 = {
    "r": 8,
    "lora_alpha": 16,
    "target_modules": ["q_proj", "v_proj"],
    "load_in_4bit": True,
    "batch_size": 1,
    "gradient_accumulation": 16,
    "reason": "4-bit 量化减少模型显存，小 rank 减少 LoRA 参数，只训练 QV 进一步减少"
}

# 场景2：追求效果
config_2 = {
    "r": 64,
    "lora_alpha": 128,
    "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    "load_in_4bit": False,  # 或 True 如果显存不够
    "batch_size": 8,
    "reason": "大 rank 增加容量，训练所有投影层，更大 batch 更稳定"
}

# 场景3：快速实验
config_3 = {
    "r": 8,
    "lora_alpha": 16,
    "target_modules": ["q_proj", "v_proj"],
    "load_in_4bit": True,
    "num_epochs": 1,
    "max_samples": 1000,
    "reason": "最小配置快速验证想法"
}
```

---

## 项目检查清单

### RAG 知识库项目

```
□ 能够上传 PDF/TXT/Markdown 文件
□ 文档被正确切分和向量化
□ 能够根据问题检索相关内容
□ 能够基于检索结果生成答案
□ 显示答案来源
□ 支持多轮对话
□ 有基本的 Web 界面
```

### SQL Agent 项目

```
□ 能够理解数据库 schema
□ 能够将自然语言转换为 SQL
□ 生成的 SQL 是安全的（只允许 SELECT）
□ 能够执行 SQL 并返回结果
□ 能够用自然语言解释结果
□ 支持错误处理和 SQL 修复
```

### LoRA 微调项目

```
□ 准备了格式正确的训练数据
□ 正确配置了 LoRA 参数
□ 训练过程中监控了 loss
□ 能够合并和导出模型
□ 对比了微调前后的效果
□ 模型能够正常推理
```

---

## 达标标准

```
□ 能独立使用 OpenAI / Claude / 本地模型 API
□ 掌握 Few-shot、CoT 等 Prompt 技巧
□ 能实现 Function Calling / Tool Use
□ 理解 RAG 的完整流程
□ 能使用 LangChain 或 LlamaIndex 构建 RAG
□ 理解 Rerank、Hybrid Search、GraphRAG
□ 理解 Agent 的四大组件
□ 能使用 LangGraph 或 AutoGen 构建 Agent
□ 理解 LoRA/QLoRA 的原理
□ 能使用 LLaMA-Factory 或 Unsloth 完成微调
□ 了解多模态 API 的使用
□ 完成至少 1 个完整项目
```

---

## 🎉 恭喜完成阶段4！

你已经掌握了 LLM 应用开发的核心技术，接下来进入：

**阶段5：部署与工程化（MLOps / LLMOps）**
- 模型量化与优化
- 推理引擎（vLLM、Ollama）
- API 服务部署
- 监控与评估

继续加油！🚀

