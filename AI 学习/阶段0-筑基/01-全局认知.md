# 🌍 01 - AI 全局认知

> 在开始学习之前，先建立对 AI 领域的整体认知

---

## 目录

1. [AI 技术地图](#1-ai-技术地图)
2. [学习范式](#2-学习范式)
3. [AI 工程师方向](#3-ai-工程师方向)
4. [学习路线建议](#4-学习路线建议)

---

## 1. AI 技术地图

### 1.1 技术演进路线

```
1950s-1980s: 符号主义 AI（专家系统、规则推理）
    ↓
1990s-2010s: 传统机器学习（决策树、SVM、随机森林）
    ↓
2012-2017: 深度学习崛起（CNN、RNN、ImageNet）
    ↓
2017-2022: Transformer 时代（BERT、GPT-2/3）
    ↓
2022-现在: 大模型时代（GPT-4、Claude、LLaMA、多模态）
    ↓
未来: AGI（通用人工智能）?
```

### 1.2 技术分层

```
应用层
├── ChatGPT、Claude、文心一言（对话）
├── Midjourney、DALL-E、Stable Diffusion（图像生成）
├── Copilot、Cursor（代码辅助）
└── 各行业应用（医疗、金融、教育...）

模型层
├── 大语言模型：GPT-4、Claude、LLaMA、Qwen、GLM
├── 多模态模型：GPT-4V、Gemini、LLaVA
├── 图像模型：Stable Diffusion、FLUX
└── 语音模型：Whisper、TTS

基础设施层
├── 训练框架：PyTorch、TensorFlow、JAX
├── 推理引擎：vLLM、TensorRT、ONNX
├── 硬件：NVIDIA GPU、TPU、华为昇腾
└── 云服务：AWS、Azure、GCP、阿里云
```

### 1.3 核心技术概念

| 概念 | 说明 | 例子 |
|------|------|------|
| **机器学习 (ML)** | 从数据中学习规律 | 预测房价、分类邮件 |
| **深度学习 (DL)** | 用神经网络学习复杂模式 | 图像识别、语音识别 |
| **大语言模型 (LLM)** | 理解和生成自然语言 | ChatGPT、Claude |
| **生成式 AI** | 创造新内容 | 文本、图像、代码生成 |
| **多模态 AI** | 处理多种类型数据 | 图文理解、视频理解 |

### 1.4 关键里程碑

| 年份 | 事件 | 影响 |
|------|------|------|
| 2012 | AlexNet 赢得 ImageNet | 深度学习爆发 |
| 2014 | GAN 提出 | 生成模型革命 |
| 2017 | Transformer 发布 | 架构革命 |
| 2018 | BERT 发布 | NLP 预训练时代 |
| 2020 | GPT-3 发布 | 大模型能力涌现 |
| 2022 | ChatGPT 发布 | AI 走进大众视野 |
| 2023 | GPT-4、多模态大模型 | 能力边界扩展 |
| 2024 | Sora、GPT-4o、开源追赶 | 多模态、实时交互 |

---

## 2. 学习范式

### 2.1 监督学习（Supervised Learning）

**特点**：有标签数据，学习输入到输出的映射

```
训练数据：(输入, 标签) pairs
         (图片, "猫")
         (邮件, "垃圾")
         (特征, 房价)

目标：学习一个函数 f，使得 f(输入) ≈ 标签
```

**应用**：
- 分类：垃圾邮件检测、图像分类
- 回归：房价预测、股价预测

```python
# 简单示例
from sklearn.linear_model import LogisticRegression

# 训练数据（有标签）
X = [[1, 2], [2, 3], [3, 4], [4, 5]]  # 特征
y = [0, 0, 1, 1]  # 标签

# 训练
model = LogisticRegression()
model.fit(X, y)

# 预测
print(model.predict([[2.5, 3.5]]))  # [0] 或 [1]
```

### 2.2 无监督学习（Unsupervised Learning）

**特点**：无标签数据，发现数据中的结构

```
训练数据：只有输入，没有标签
         [用户A的购买记录]
         [用户B的购买记录]
         ...

目标：发现数据中的模式、结构、分组
```

**应用**：
- 聚类：客户分群、异常检测
- 降维：数据可视化、特征压缩

```python
from sklearn.cluster import KMeans

# 无标签数据
X = [[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]]

# 聚类
kmeans = KMeans(n_clusters=2)
labels = kmeans.fit_predict(X)
print(labels)  # [0, 0, 1, 1, 0, 1] 分成两组
```

### 2.3 强化学习（Reinforcement Learning）

**特点**：通过与环境交互学习，获得奖励信号

```
智能体（Agent）←→ 环境（Environment）
                ↓
            状态（State）
                ↓
            动作（Action）
                ↓
            奖励（Reward）

目标：最大化累计奖励
```

**应用**：
- 游戏 AI：AlphaGo、Atari 游戏
- 机器人控制：自动驾驶、机械臂
- 推荐系统：个性化推荐

### 2.4 自监督学习（Self-Supervised Learning）

**特点**：从数据本身构造标签，不需要人工标注

```
预训练任务：
- 语言模型：预测下一个词
  "今天天气很____" → "好"

- 掩码语言模型：预测被遮挡的词
  "今天[MASK]很好" → "天气"

- 对比学习：区分相似和不相似
```

**应用**：
- GPT 系列：预测下一个 token
- BERT：预测被 mask 的 token
- 这是大模型能力的核心来源！

### 2.5 RLHF（人类反馈强化学习）

**特点**：用人类偏好来训练模型

```
流程：
1. 预训练大模型
2. 人类对模型输出打分（哪个更好）
3. 训练奖励模型学习人类偏好
4. 用强化学习优化原模型
```

**作用**：
- 让模型输出更符合人类期望
- 减少有害、偏见内容
- ChatGPT 成功的关键技术之一

---

## 3. AI 工程师方向

### 3.1 方向概览

```
AI 工程师
├── 算法研究（Algorithm Research）
│   ├── 模型架构创新
│   ├── 训练方法改进
│   └── 学术论文发表
│
├── 应用开发（AI Application）
│   ├── RAG 应用开发
│   ├── Agent 开发
│   ├── Prompt Engineering
│   └── 产品落地
│
├── 模型训练（Training Engineer）
│   ├── 预训练
│   ├── 微调（Fine-tuning）
│   ├── 数据工程
│   └── 分布式训练
│
└── 部署运维（MLOps/LLMOps）
    ├── 模型部署
    ├── 推理优化
    ├── 监控运维
    └── 成本优化
```

### 3.2 各方向详解

| 方向 | 核心技能 | 适合人群 | 入门难度 |
|------|---------|---------|---------|
| **算法研究** | 数学、深度学习、论文阅读 | 数学好、喜欢研究 | ⭐⭐⭐⭐⭐ |
| **应用开发** | Python、API 调用、产品思维 | 工程能力强、喜欢做产品 | ⭐⭐ |
| **模型训练** | PyTorch、分布式、GPU | 工程能力强、资源充足 | ⭐⭐⭐⭐ |
| **部署运维** | Docker、K8s、推理优化 | 后端工程师转型 | ⭐⭐⭐ |

### 3.3 技能要求

#### 应用开发工程师（最推荐入门）

```
必备技能：
├── Python 编程
├── LangChain / LlamaIndex
├── Prompt Engineering
├── RAG（检索增强生成）
├── API 调用与集成
└── 基本的产品思维

加分项：
├── 前端开发
├── 数据库
└── 云服务使用
```

#### 算法工程师

```
必备技能：
├── 扎实的数学基础（线性代数、概率论、优化）
├── 深度学习理论与实践
├── PyTorch 熟练使用
├── 论文阅读能力
└── 英语能力

加分项：
├── 顶会论文发表
├── 知名开源项目贡献
└── 竞赛获奖
```

---

## 4. 学习路线建议

### 4.1 推荐路线：应用开发方向

```
阶段 0：筑基（2-4 周）
  ↓
阶段 1：传统机器学习（2-3 周）
  ↓
阶段 2：深度学习基础（3-4 周）
  ↓
阶段 3：Transformer 与大模型（3-4 周）
  ↓
阶段 4：LLM 应用开发（4-6 周）  ← 核心！
  - Prompt Engineering
  - RAG
  - Agent
  ↓
阶段 5：部署与工程化（2-3 周）
  ↓
阶段 6：职业发展
```

### 4.2 不同起点的建议

| 背景 | 建议 |
|------|------|
| **零基础** | 从阶段 0 开始，扎实基础 |
| **会 Python** | 快速过阶段 0，重点学 ML |
| **后端工程师** | 重点学 LLM 应用开发和部署 |
| **数据分析师** | 重点学深度学习和大模型 |
| **前端工程师** | 重点学 API 调用和应用开发 |

### 4.3 学习原则

```
1. 实践优先
   - 每学一个概念就写代码验证
   - 多做项目，少背理论

2. 循序渐进
   - 不要跳过基础
   - 不懂的先标记，后面会串联

3. 保持好奇
   - 关注最新技术动态
   - 但不要追风口，打好基础

4. 学会搜索
   - 善用 Google、GitHub、论文
   - AI 工具本身就是好的学习助手
```

---

## 练习

1. 用自己的话解释：什么是机器学习？什么是深度学习？什么是大语言模型？
2. 列出 3 个监督学习的实际应用场景
3. RLHF 解决了什么问题？
4. 你计划走哪个方向？为什么？

---

## ➡️ 下一步

学完本节后，继续学习 [02-Python基础.md](./02-Python基础.md)

