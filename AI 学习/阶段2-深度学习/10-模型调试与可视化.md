# ğŸ” 10 - æ¨¡å‹è°ƒè¯•ä¸å¯è§†åŒ–

> å­¦ä¼šè°ƒè¯•ç¥ç»ç½‘ç»œã€å¯è§†åŒ–ä¸­é—´å±‚ã€è¯Šæ–­è®­ç»ƒé—®é¢˜

---

## ç›®å½•

1. [æ¨¡å‹è°ƒè¯•çš„é‡è¦æ€§](#1-æ¨¡å‹è°ƒè¯•çš„é‡è¦æ€§)
2. [ç‰¹å¾å›¾å¯è§†åŒ–](#2-ç‰¹å¾å›¾å¯è§†åŒ–)
3. [å·ç§¯æ ¸å¯è§†åŒ–](#3-å·ç§¯æ ¸å¯è§†åŒ–)
4. [æ¢¯åº¦å¯è§†åŒ–](#4-æ¢¯åº¦å¯è§†åŒ–)
5. [æ¿€æ´»å€¼åˆ†æ](#5-æ¿€æ´»å€¼åˆ†æ)
6. [è®­ç»ƒè¿‡ç¨‹è¯Šæ–­](#6-è®­ç»ƒè¿‡ç¨‹è¯Šæ–­)
7. [å¸¸è§é—®é¢˜æ’æŸ¥](#7-å¸¸è§é—®é¢˜æ’æŸ¥)
8. [ç»ƒä¹ é¢˜](#8-ç»ƒä¹ é¢˜)

---

## 1. æ¨¡å‹è°ƒè¯•çš„é‡è¦æ€§

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦å¯è§†åŒ–

```
æ¨¡å‹æ˜¯"é»‘ç›’"å—ï¼Ÿ

ä¼ ç»Ÿè§‚ç‚¹ï¼šç¥ç»ç½‘ç»œéš¾ä»¥è§£é‡Š
ç°ä»£è§‚ç‚¹ï¼šé€šè¿‡å¯è§†åŒ–å¯ä»¥ç†è§£æ¨¡å‹åœ¨å­¦ä»€ä¹ˆ

å¯è§†åŒ–çš„ä½œç”¨ï¼š
â”œâ”€â”€ è°ƒè¯•ï¼šå‘ç°æ¨¡å‹é—®é¢˜ï¼ˆå¦‚æ²¡æœ‰å­¦åˆ°æœ‰æ„ä¹‰çš„ç‰¹å¾ï¼‰
â”œâ”€â”€ ç†è§£ï¼šäº†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹
â”œâ”€â”€ ä¼˜åŒ–ï¼šæŒ‡å¯¼æ¨¡å‹æ”¹è¿›æ–¹å‘
â””â”€â”€ ä¿¡ä»»ï¼šå¢åŠ å¯¹æ¨¡å‹é¢„æµ‹çš„ä¿¡å¿ƒ
```

### 1.2 è°ƒè¯•å·¥å…·æ¦‚è§ˆ

```python
# å¸¸ç”¨å·¥å…·
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np

# é«˜çº§å¯è§†åŒ–å·¥å…·
# pip install torchviz  # è®¡ç®—å›¾å¯è§†åŒ–
# pip install captum   # æ¨¡å‹è§£é‡Šæ€§ï¼ˆPyTorchå®˜æ–¹ï¼‰
# pip install grad-cam # Grad-CAM å¯è§†åŒ–
```

---

## 2. ç‰¹å¾å›¾å¯è§†åŒ–

### 2.1 æå–ä¸­é—´å±‚è¾“å‡º

```python
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = models.resnet18(pretrained=True)
model.eval()

# å­˜å‚¨ä¸­é—´å±‚è¾“å‡ºçš„å­—å…¸
activations = {}

# æ³¨å†Œé’©å­å‡½æ•°
def get_activation(name):
    def hook(model, input, output):
        activations[name] = output.detach()
    return hook

# åœ¨æƒ³è¦è§‚å¯Ÿçš„å±‚ä¸Šæ³¨å†Œé’©å­
model.conv1.register_forward_hook(get_activation('conv1'))
model.layer1.register_forward_hook(get_activation('layer1'))
model.layer2.register_forward_hook(get_activation('layer2'))
model.layer3.register_forward_hook(get_activation('layer3'))
model.layer4.register_forward_hook(get_activation('layer4'))

# åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
def load_image(image_path, size=224):
    transform = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0), image

# ç¤ºä¾‹ï¼šä½¿ç”¨ä¸€å¼ æµ‹è¯•å›¾åƒ
# x, original_img = load_image('test_image.jpg')

# ä½¿ç”¨éšæœºå›¾åƒæ¼”ç¤º
x = torch.randn(1, 3, 224, 224)

# å‰å‘ä¼ æ’­
with torch.no_grad():
    output = model(x)

# æŸ¥çœ‹æ¿€æ´»å€¼
for name, activation in activations.items():
    print(f"{name}: {activation.shape}")
```

### 2.2 å¯è§†åŒ–ç‰¹å¾å›¾

```python
def visualize_feature_maps(activation, num_cols=8, figsize=(16, 8)):
    """å¯è§†åŒ–ç‰¹å¾å›¾"""
    # activation: [1, C, H, W]
    feature_maps = activation.squeeze(0).cpu().numpy()
    num_channels = feature_maps.shape[0]
    num_rows = (num_channels + num_cols - 1) // num_cols

    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()

    for idx in range(num_channels):
        if idx < len(axes):
            axes[idx].imshow(feature_maps[idx], cmap='viridis')
            axes[idx].axis('off')
            axes[idx].set_title(f'Ch {idx}', fontsize=8)

    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(num_channels, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.show()

# å¯è§†åŒ– conv1 çš„ç‰¹å¾å›¾
print("Conv1 ç‰¹å¾å›¾ï¼š")
visualize_feature_maps(activations['conv1'], num_cols=8)

# å¯è§†åŒ– layer1 çš„ç‰¹å¾å›¾
print("Layer1 ç‰¹å¾å›¾ï¼š")
visualize_feature_maps(activations['layer1'], num_cols=8)
```

### 2.3 ç‰¹å¾å›¾ç»Ÿè®¡åˆ†æ

```python
def analyze_feature_maps(activations_dict):
    """åˆ†æå„å±‚ç‰¹å¾å›¾çš„ç»Ÿè®¡ä¿¡æ¯"""
    print("=" * 60)
    print(f"{'Layer':<15} {'Shape':<20} {'Mean':<10} {'Std':<10} {'Sparsity':<10}")
    print("=" * 60)

    for name, activation in activations_dict.items():
        feat = activation.squeeze(0)
        mean = feat.mean().item()
        std = feat.std().item()
        # ç¨€ç–åº¦ï¼šæ¥è¿‘ 0 çš„æ¯”ä¾‹
        sparsity = (feat.abs() < 0.01).float().mean().item()

        print(f"{name:<15} {str(list(feat.shape)):<20} {mean:<10.4f} {std:<10.4f} {sparsity:<10.2%}")

analyze_feature_maps(activations)
```

---

## 3. å·ç§¯æ ¸å¯è§†åŒ–

### 3.1 ç›´æ¥å¯è§†åŒ–å·ç§¯æ ¸æƒé‡

```python
def visualize_conv_kernels(conv_layer, num_cols=8, figsize=(16, 8)):
    """å¯è§†åŒ–å·ç§¯æ ¸æƒé‡"""
    # è·å–æƒé‡ [out_channels, in_channels, H, W]
    weights = conv_layer.weight.data.cpu()

    # å¯¹äºç¬¬ä¸€å±‚ï¼ˆRGB è¾“å…¥ï¼‰ï¼Œå¯ä»¥ç›´æ¥å¯è§†åŒ–
    if weights.shape[1] == 3:
        # å½’ä¸€åŒ–åˆ° [0, 1]
        weights_normalized = (weights - weights.min()) / (weights.max() - weights.min())

        num_kernels = weights.shape[0]
        num_rows = (num_kernels + num_cols - 1) // num_cols

        fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
        axes = axes.flatten()

        for idx in range(num_kernels):
            if idx < len(axes):
                # è½¬ç½®ä¸º [H, W, C]
                kernel = weights_normalized[idx].permute(1, 2, 0).numpy()
                axes[idx].imshow(kernel)
                axes[idx].axis('off')
                axes[idx].set_title(f'Kernel {idx}', fontsize=8)

        for idx in range(num_kernels, len(axes)):
            axes[idx].axis('off')

        plt.suptitle('Conv1 Kernels (RGB)', fontsize=14)
        plt.tight_layout()
        plt.show()
    else:
        # å¯¹äºé RGB è¾“å…¥å±‚ï¼Œæ˜¾ç¤ºå•é€šé“åˆ‡ç‰‡
        print(f"å·ç§¯æ ¸å½¢çŠ¶: {weights.shape}")
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªè¾“å…¥é€šé“çš„æ‰€æœ‰è¾“å‡ºæ ¸
        kernels = weights[:, 0, :, :]  # [out_channels, H, W]

        num_kernels = min(64, kernels.shape[0])
        num_rows = (num_kernels + num_cols - 1) // num_cols

        fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
        axes = axes.flatten()

        for idx in range(num_kernels):
            axes[idx].imshow(kernels[idx].numpy(), cmap='gray')
            axes[idx].axis('off')

        for idx in range(num_kernels, len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()
        plt.show()

# å¯è§†åŒ–ç¬¬ä¸€å±‚å·ç§¯æ ¸
visualize_conv_kernels(model.conv1)
```

### 3.2 åˆ†æå·ç§¯æ ¸ç»Ÿè®¡

```python
def analyze_conv_layers(model):
    """åˆ†ææ¨¡å‹ä¸­æ‰€æœ‰å·ç§¯å±‚çš„æƒé‡ç»Ÿè®¡"""
    print("=" * 70)
    print(f"{'Layer':<30} {'Shape':<25} {'Mean':<10} {'Std':<10}")
    print("=" * 70)

    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            weight = module.weight.data
            print(f"{name:<30} {str(list(weight.shape)):<25} "
                  f"{weight.mean().item():<10.4f} {weight.std().item():<10.4f}")

analyze_conv_layers(model)
```

---

## 4. æ¢¯åº¦å¯è§†åŒ–

### 4.1 Grad-CAM

Grad-CAM æ˜¾ç¤ºæ¨¡å‹"å…³æ³¨"å›¾åƒçš„å“ªäº›åŒºåŸŸã€‚

```python
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt

class GradCAM:
    """Grad-CAM å®ç°"""
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None

        # æ³¨å†Œé’©å­
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output.detach()

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0].detach()

    def __call__(self, x, class_idx=None):
        # å‰å‘ä¼ æ’­
        self.model.eval()
        output = self.model(x)

        if class_idx is None:
            class_idx = output.argmax(dim=1)

        # åå‘ä¼ æ’­
        self.model.zero_grad()
        one_hot = torch.zeros_like(output)
        one_hot[0, class_idx] = 1
        output.backward(gradient=one_hot, retain_graph=True)

        # è®¡ç®—æƒé‡
        weights = self.gradients.mean(dim=(2, 3), keepdim=True)  # GAP

        # åŠ æƒæ±‚å’Œ
        cam = (weights * self.activations).sum(dim=1, keepdim=True)
        cam = F.relu(cam)  # ReLU

        # å½’ä¸€åŒ–
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)

        # ä¸Šé‡‡æ ·åˆ°åŸå›¾å¤§å°
        cam = F.interpolate(cam, size=x.shape[2:], mode='bilinear', align_corners=False)

        return cam.squeeze().cpu().numpy()

# ä½¿ç”¨ Grad-CAM
model = models.resnet18(pretrained=True)
grad_cam = GradCAM(model, model.layer4[-1])

# æµ‹è¯•å›¾åƒ
x = torch.randn(1, 3, 224, 224)
x.requires_grad = True

# è·å–çƒ­åŠ›å›¾
heatmap = grad_cam(x)

# å¯è§†åŒ–
def show_cam_on_image(img, mask, alpha=0.5):
    """å°† CAM å åŠ åˆ°åŸå›¾ä¸Š"""
    heatmap = plt.cm.jet(mask)[:, :, :3]

    # å¦‚æœ img æ˜¯ tensor
    if isinstance(img, torch.Tensor):
        img = img.squeeze().permute(1, 2, 0).numpy()
        # åå½’ä¸€åŒ–
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        img = std * img + mean
        img = np.clip(img, 0, 1)

    cam_img = heatmap * alpha + img * (1 - alpha)
    return np.clip(cam_img, 0, 1)

# æ˜¾ç¤ºç»“æœ
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# åŸå›¾
axes[0].imshow(x.squeeze().permute(1, 2, 0).detach().numpy() * 0.5 + 0.5)
axes[0].set_title('Original Image')
axes[0].axis('off')

# çƒ­åŠ›å›¾
axes[1].imshow(heatmap, cmap='jet')
axes[1].set_title('Grad-CAM Heatmap')
axes[1].axis('off')

# å åŠ 
axes[2].imshow(show_cam_on_image(x, heatmap))
axes[2].set_title('Overlay')
axes[2].axis('off')

plt.tight_layout()
plt.show()
```

### 4.2 æ¢¯åº¦æµåˆ†æ

```python
def plot_gradient_flow(model):
    """å¯è§†åŒ–æ¢¯åº¦æµåŠ¨"""
    ave_grads = []
    max_grads = []
    layers = []

    for name, param in model.named_parameters():
        if param.requires_grad and param.grad is not None:
            layers.append(name)
            ave_grads.append(param.grad.abs().mean().item())
            max_grads.append(param.grad.abs().max().item())

    plt.figure(figsize=(14, 6))
    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.3, lw=1, color="c", label="max gradient")
    plt.bar(np.arange(len(ave_grads)), ave_grads, alpha=0.3, lw=1, color="b", label="mean gradient")
    plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color="k")
    plt.xticks(range(len(layers)), layers, rotation=90, fontsize=8)
    plt.xlim(left=0, right=len(ave_grads))
    plt.xlabel("Layers")
    plt.ylabel("Gradient")
    plt.title("Gradient Flow")
    plt.legend()
    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ç¤ºä¾‹
# å…ˆè¿›è¡Œä¸€æ¬¡å‰å‘+åå‘ä¼ æ’­
model = nn.Sequential(
    nn.Linear(10, 64),
    nn.ReLU(),
    nn.Linear(64, 64),
    nn.ReLU(),
    nn.Linear(64, 2)
)

x = torch.randn(32, 10)
y = torch.randint(0, 2, (32,))

output = model(x)
loss = nn.CrossEntropyLoss()(output, y)
loss.backward()

plot_gradient_flow(model)
```

---

## 5. æ¿€æ´»å€¼åˆ†æ

### 5.1 æ¿€æ´»å€¼åˆ†å¸ƒ

```python
def analyze_activations(model, data_loader, device='cpu'):
    """åˆ†ææ¨¡å‹å„å±‚çš„æ¿€æ´»å€¼åˆ†å¸ƒ"""
    model.eval()
    model.to(device)

    # æ”¶é›†æ¿€æ´»å€¼
    activation_stats = {}
    hooks = []

    def make_hook(name):
        def hook(module, input, output):
            if name not in activation_stats:
                activation_stats[name] = {'values': []}
            activation_stats[name]['values'].append(output.detach().cpu())
        return hook

    # æ³¨å†Œé’©å­
    for name, module in model.named_modules():
        if isinstance(module, (nn.ReLU, nn.GELU, nn.SiLU)):
            hooks.append(module.register_forward_hook(make_hook(name)))

    # æ”¶é›†å‡ ä¸ª batch çš„æ¿€æ´»å€¼
    with torch.no_grad():
        for i, (data, _) in enumerate(data_loader):
            if i >= 10:  # åªæ”¶é›† 10 ä¸ª batch
                break
            data = data.to(device)
            _ = model(data)

    # ç§»é™¤é’©å­
    for hook in hooks:
        hook.remove()

    # åˆ†æç»Ÿè®¡
    print("=" * 60)
    print(f"{'Layer':<30} {'Mean':<10} {'Std':<10} {'Dead%':<10}")
    print("=" * 60)

    for name, stats in activation_stats.items():
        all_values = torch.cat(stats['values'], dim=0)
        mean = all_values.mean().item()
        std = all_values.std().item()
        dead_ratio = (all_values == 0).float().mean().item()

        print(f"{name:<30} {mean:<10.4f} {std:<10.4f} {dead_ratio:<10.2%}")

    return activation_stats
```

### 5.2 æ£€æµ‹æ­»ç¥ç»å…ƒ

```python
def check_dead_neurons(model, data_loader, device='cpu', threshold=0.01):
    """æ£€æµ‹"æ­»äº¡"çš„ç¥ç»å…ƒï¼ˆå§‹ç»ˆè¾“å‡º 0ï¼‰"""
    model.eval()
    model.to(device)

    dead_neurons_info = {}

    for name, module in model.named_modules():
        if isinstance(module, nn.ReLU):
            activation_sum = None
            count = 0

            def make_hook(name):
                def hook(m, inp, out):
                    nonlocal activation_sum, count
                    if activation_sum is None:
                        activation_sum = torch.zeros_like(out[0])
                    activation_sum += (out > 0).float().sum(dim=0)
                    count += out.shape[0]
                return hook

            h = module.register_forward_hook(make_hook(name))

            with torch.no_grad():
                for i, (data, _) in enumerate(data_loader):
                    if i >= 10:
                        break
                    data = data.to(device)
                    _ = model(data)

            h.remove()

            if activation_sum is not None:
                activation_rate = activation_sum / count
                dead_ratio = (activation_rate < threshold).float().mean().item()
                dead_neurons_info[name] = {
                    'dead_ratio': dead_ratio,
                    'total_neurons': activation_sum.numel()
                }

    print("\næ­»ç¥ç»å…ƒæ£€æµ‹ç»“æœ:")
    print("=" * 50)
    for name, info in dead_neurons_info.items():
        print(f"{name}: {info['dead_ratio']:.2%} æ­»äº¡ "
              f"({int(info['dead_ratio'] * info['total_neurons'])} / {info['total_neurons']})")

    return dead_neurons_info
```

---

## 6. è®­ç»ƒè¿‡ç¨‹è¯Šæ–­

### 6.1 Loss æ›²çº¿åˆ†æ

```python
import matplotlib.pyplot as plt

def diagnose_training(train_losses, val_losses, train_accs=None, val_accs=None):
    """è¯Šæ–­è®­ç»ƒè¿‡ç¨‹"""
    fig, axes = plt.subplots(1, 2 if train_accs else 1, figsize=(14 if train_accs else 8, 5))

    if train_accs:
        ax1, ax2 = axes
    else:
        ax1 = axes

    # Loss æ›²çº¿
    ax1.plot(train_losses, label='Train Loss', linewidth=2)
    ax1.plot(val_losses, label='Val Loss', linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Loss Curves')
    ax1.legend()
    ax1.grid(True)

    # è¯Šæ–­ä¿¡æ¯
    train_final = train_losses[-1]
    val_final = val_losses[-1]
    val_min = min(val_losses)
    val_min_epoch = val_losses.index(val_min)

    # åˆ¤æ–­é—®é¢˜
    issues = []

    # 1. è¿‡æ‹Ÿåˆæ£€æµ‹
    if val_final > val_min * 1.1 and len(val_losses) > val_min_epoch + 5:
        issues.append(f"âš ï¸ è¿‡æ‹Ÿåˆï¼šVal Loss åœ¨ Epoch {val_min_epoch} åä¸Šå‡")
        # æ ‡è®°æœ€ä½³ç‚¹
        ax1.axvline(val_min_epoch, color='red', linestyle='--', alpha=0.5)
        ax1.scatter([val_min_epoch], [val_min], color='red', s=100, zorder=5)

    # 2. æ¬ æ‹Ÿåˆæ£€æµ‹
    if train_final > train_losses[0] * 0.5:
        issues.append("âš ï¸ å¯èƒ½æ¬ æ‹Ÿåˆï¼šTrain Loss ä¸‹é™ä¸å¤Ÿ")

    # 3. è®­ç»ƒä¸ç¨³å®š
    train_diff = [abs(train_losses[i] - train_losses[i-1]) for i in range(1, len(train_losses))]
    if max(train_diff) > train_losses[0] * 0.5:
        issues.append("âš ï¸ è®­ç»ƒä¸ç¨³å®šï¼šLoss æ³¢åŠ¨è¾ƒå¤§")

    # 4. Gap è¿‡å¤§
    gap = val_final - train_final
    if gap > train_final * 0.5:
        issues.append(f"âš ï¸ Train-Val Gap è¿‡å¤§ï¼š{gap:.4f}")

    if train_accs:
        # Accuracy æ›²çº¿
        ax2.plot(train_accs, label='Train Acc', linewidth=2)
        ax2.plot(val_accs, label='Val Acc', linewidth=2)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.set_title('Accuracy Curves')
        ax2.legend()
        ax2.grid(True)

    plt.tight_layout()
    plt.show()

    # æ‰“å°è¯Šæ–­ç»“æœ
    print("\n" + "=" * 50)
    print("è®­ç»ƒè¯Šæ–­æŠ¥å‘Š")
    print("=" * 50)
    print(f"Train Loss (final): {train_final:.4f}")
    print(f"Val Loss (final): {val_final:.4f}")
    print(f"Val Loss (best): {val_min:.4f} @ Epoch {val_min_epoch}")
    print(f"Train-Val Gap: {gap:.4f}")

    if issues:
        print("\nå‘ç°çš„é—®é¢˜:")
        for issue in issues:
            print(f"  {issue}")
    else:
        print("\nâœ… è®­ç»ƒçœ‹èµ·æ¥æ­£å¸¸")

    return issues

# æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•
train_losses = [2.0, 1.5, 1.2, 0.9, 0.7, 0.5, 0.4, 0.3, 0.25, 0.2]
val_losses = [2.1, 1.6, 1.3, 1.0, 0.85, 0.8, 0.82, 0.85, 0.9, 0.95]
train_accs = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.92, 0.95]
val_accs = [0.28, 0.38, 0.48, 0.58, 0.65, 0.7, 0.68, 0.66, 0.64, 0.62]

diagnose_training(train_losses, val_losses, train_accs, val_accs)
```

### 6.2 å­¦ä¹ ç‡æŸ¥æ‰¾å™¨

```python
def find_learning_rate(model, train_loader, criterion, device,
                       start_lr=1e-7, end_lr=10, num_iters=100):
    """å­¦ä¹ ç‡æŸ¥æ‰¾å™¨ï¼šæ‰¾åˆ°æœ€ä½³å­¦ä¹ ç‡èŒƒå›´"""
    import copy

    # ä¿å­˜åŸå§‹å‚æ•°
    model_state = copy.deepcopy(model.state_dict())

    model.train()
    model.to(device)

    optimizer = torch.optim.SGD(model.parameters(), lr=start_lr)

    # å­¦ä¹ ç‡è°ƒåº¦
    lr_mult = (end_lr / start_lr) ** (1 / num_iters)

    lrs = []
    losses = []
    best_loss = float('inf')

    data_iter = iter(train_loader)

    for i in range(num_iters):
        try:
            data, target = next(data_iter)
        except StopIteration:
            data_iter = iter(train_loader)
            data, target = next(data_iter)

        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)

        # å¦‚æœ loss çˆ†ç‚¸äº†ï¼Œåœæ­¢
        if loss.item() > 4 * best_loss:
            break

        if loss.item() < best_loss:
            best_loss = loss.item()

        losses.append(loss.item())
        lrs.append(optimizer.param_groups[0]['lr'])

        loss.backward()
        optimizer.step()

        # æ›´æ–°å­¦ä¹ ç‡
        for param_group in optimizer.param_groups:
            param_group['lr'] *= lr_mult

    # æ¢å¤åŸå§‹å‚æ•°
    model.load_state_dict(model_state)

    # å¯è§†åŒ–
    plt.figure(figsize=(10, 6))
    plt.plot(lrs, losses)
    plt.xscale('log')
    plt.xlabel('Learning Rate (log scale)')
    plt.ylabel('Loss')
    plt.title('Learning Rate Finder')

    # æ‰¾åˆ°æœ€é™¡ä¸‹é™ç‚¹
    gradients = np.gradient(losses)
    min_grad_idx = np.argmin(gradients)
    suggested_lr = lrs[min_grad_idx]

    plt.axvline(suggested_lr, color='red', linestyle='--',
                label=f'Suggested LR: {suggested_lr:.2e}')
    plt.legend()
    plt.grid(True)
    plt.show()

    print(f"å»ºè®®çš„å­¦ä¹ ç‡: {suggested_lr:.2e}")

    return lrs, losses, suggested_lr
```

---

## 7. å¸¸è§é—®é¢˜æ’æŸ¥

### 7.1 é—®é¢˜è¯Šæ–­æ¸…å•

```
è®­ç»ƒ Loss ä¸ä¸‹é™ï¼š
â”œâ”€â”€ æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚ï¼ˆå¤ªå¤§/å¤ªå°ï¼‰
â”œâ”€â”€ æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®åŠ è½½
â”œâ”€â”€ æ£€æŸ¥æ ‡ç­¾æ˜¯å¦æ­£ç¡®
â”œâ”€â”€ æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡äºç®€å•
â””â”€â”€ å°è¯•å…ˆè®©æ¨¡å‹è¿‡æ‹Ÿåˆå°æ•°æ®

Loss å˜æˆ NaNï¼š
â”œâ”€â”€ æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦å¤ªå¤§
â”œâ”€â”€ æ£€æŸ¥æ˜¯å¦æœ‰é™¤é›¶æ“ä½œ
â”œâ”€â”€ æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰ NaN/Inf
â”œâ”€â”€ æ·»åŠ æ¢¯åº¦è£å‰ª
â””â”€â”€ å°è¯•å‡å°åˆå§‹å­¦ä¹ ç‡

Val Loss éœ‡è¡ï¼š
â”œâ”€â”€ å‡å°å­¦ä¹ ç‡
â”œâ”€â”€ å¢å¤§ batch size
â”œâ”€â”€ ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
â””â”€â”€ æ£€æŸ¥éªŒè¯é›†æ˜¯å¦å¤ªå°

è¿‡æ‹Ÿåˆï¼š
â”œâ”€â”€ å¢åŠ è®­ç»ƒæ•°æ® / æ•°æ®å¢å¼º
â”œâ”€â”€ å¢åŠ æ­£åˆ™åŒ–ï¼ˆDropout, weight_decayï¼‰
â”œâ”€â”€ å‡å°‘æ¨¡å‹å¤æ‚åº¦
â”œâ”€â”€ ä½¿ç”¨ Early Stopping
â””â”€â”€ ä½¿ç”¨ BatchNorm

æ¬ æ‹Ÿåˆï¼š
â”œâ”€â”€ å¢åŠ æ¨¡å‹å¤æ‚åº¦ï¼ˆæ›´æ·±/æ›´å®½ï¼‰
â”œâ”€â”€ å‡å°‘æ­£åˆ™åŒ–
â”œâ”€â”€ è®­ç»ƒæ›´é•¿æ—¶é—´
â”œâ”€â”€ æ£€æŸ¥ç‰¹å¾å·¥ç¨‹
â””â”€â”€ å°è¯•æ›´å¼ºçš„æ¨¡å‹æ¶æ„
```

### 7.2 è°ƒè¯•å·¥å…·å‡½æ•°

```python
def debug_forward_pass(model, sample_input, device='cpu'):
    """è°ƒè¯•å‰å‘ä¼ æ’­ï¼šæ£€æŸ¥æ¯å±‚çš„è¾“å‡º"""
    model.eval()
    model.to(device)
    sample_input = sample_input.to(device)

    print("=" * 70)
    print(f"{'Layer':<40} {'Output Shape':<20} {'Has NaN':<10}")
    print("=" * 70)

    x = sample_input
    has_issue = False

    for name, module in model.named_children():
        try:
            x = module(x)
            has_nan = torch.isnan(x).any().item()
            has_inf = torch.isinf(x).any().item()

            status = ""
            if has_nan:
                status = "âš ï¸ NaN"
                has_issue = True
            elif has_inf:
                status = "âš ï¸ Inf"
                has_issue = True

            print(f"{name:<40} {str(list(x.shape)):<20} {status}")
        except Exception as e:
            print(f"{name:<40} ERROR: {str(e)}")
            has_issue = True
            break

    if not has_issue:
        print("\nâœ… å‰å‘ä¼ æ’­æ­£å¸¸")
    else:
        print("\nâŒ å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°æ ‡è®°å±‚")

    return x


def check_data_loader(data_loader, num_batches=3):
    """æ£€æŸ¥ DataLoader æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("=" * 50)
    print("DataLoader æ£€æŸ¥")
    print("=" * 50)

    for i, (data, target) in enumerate(data_loader):
        if i >= num_batches:
            break

        print(f"\nBatch {i + 1}:")
        print(f"  Data shape: {data.shape}")
        print(f"  Data dtype: {data.dtype}")
        print(f"  Data range: [{data.min().item():.4f}, {data.max().item():.4f}]")
        print(f"  Target shape: {target.shape}")
        print(f"  Target dtype: {target.dtype}")

        if torch.isnan(data).any():
            print("  âš ï¸ Data contains NaN!")
        if torch.isinf(data).any():
            print("  âš ï¸ Data contains Inf!")

        # æ£€æŸ¥æ ‡ç­¾
        if target.dtype in [torch.long, torch.int]:
            print(f"  Target unique values: {torch.unique(target).tolist()}")

    print("\nâœ… DataLoader æ£€æŸ¥å®Œæˆ")
```

---

## 8. ç»ƒä¹ é¢˜

### åŸºç¡€ç»ƒä¹ 

1. åŠ è½½é¢„è®­ç»ƒçš„ ResNet18ï¼Œå¯è§†åŒ– layer4 çš„ç‰¹å¾å›¾
2. å®ç°æ¢¯åº¦æµå¯è§†åŒ–ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦æ¶ˆå¤±
3. ä½¿ç”¨å­¦ä¹ ç‡æŸ¥æ‰¾å™¨ï¼Œæ‰¾åˆ°åˆé€‚çš„å­¦ä¹ ç‡

### è¿›é˜¶ç»ƒä¹ 

4. å®ç°å®Œæ•´çš„ Grad-CAMï¼Œå¹¶åœ¨ CIFAR-10 åˆ†ç±»ä»»åŠ¡ä¸Šä½¿ç”¨
5. ç¼–å†™è®­ç»ƒè¯Šæ–­å‡½æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ

### å‚è€ƒç­”æ¡ˆ

<details>
<summary>ç»ƒä¹  1 å‚è€ƒç­”æ¡ˆ</summary>

```python
import torch
import torchvision.models as models
import matplotlib.pyplot as plt

# åŠ è½½é¢„è®­ç»ƒ ResNet18
model = models.resnet18(pretrained=True)
model.eval()

# å­˜å‚¨ layer4 è¾“å‡º
activation = {}
def hook(module, input, output):
    activation['layer4'] = output.detach()

model.layer4.register_forward_hook(hook)

# å‰å‘ä¼ æ’­
x = torch.randn(1, 3, 224, 224)
with torch.no_grad():
    _ = model(x)

# å¯è§†åŒ–
feat = activation['layer4'].squeeze(0)  # [512, 7, 7]

fig, axes = plt.subplots(8, 8, figsize=(16, 16))
for i, ax in enumerate(axes.flatten()):
    if i < feat.shape[0]:
        ax.imshow(feat[i].cpu().numpy(), cmap='viridis')
    ax.axis('off')

plt.suptitle('ResNet18 Layer4 Feature Maps')
plt.tight_layout()
plt.show()
```

</details>

---

## â¡ï¸ ä¸‹ä¸€æ­¥

å­¦å®Œæœ¬èŠ‚åï¼Œç»§ç»­å­¦ä¹  [11-é¡¹ç›®-MNISTå…¥é—¨.md](./11-é¡¹ç›®-MNISTå…¥é—¨.md)

