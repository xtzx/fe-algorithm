# ❓ 08 - 面试常见问题集

> 技术问题、项目问题、行为问题及回答思路

---

## 技术基础问题

### LLM 基础

```
Q: 大模型的训练分为哪几个阶段？

A:
1. 预训练（Pre-training）
   - 大规模无监督学习
   - 学习语言知识和世界知识
   - 需要大量算力

2. 指令微调（Instruction Tuning / SFT）
   - 有监督学习
   - 学习遵循指令的能力
   - 数据质量重要

3. 对齐训练（RLHF / DPO）
   - 人类反馈强化学习
   - 让模型更符合人类偏好
   - 减少有害输出
```

```
Q: Decoder-only 和 Encoder-Decoder 有什么区别？

A:
Decoder-only（GPT 系列）：
- 单向注意力（只看前面）
- 自回归生成
- 适合文本生成任务
- 现代大模型主流

Encoder-Decoder（T5、BART）：
- Encoder 双向，Decoder 单向
- Encoder 理解输入，Decoder 生成输出
- 适合翻译、摘要等 Seq2Seq 任务
```

```
Q: 温度（Temperature）参数的作用是什么？

A:
- 控制输出的随机性
- Temperature 越高，分布越平滑，越随机
- Temperature 越低，分布越尖锐，越确定
- T=0：贪婪解码，总是选最大概率
- T=1：标准采样
- T>1：更有创意但可能不连贯
```

### RAG 问题

```
Q: 你们的文档是怎么切分的？

A:
我们采用了分层切分策略：

1. 按语义切分（RecursiveCharacterTextSplitter）
   - 优先在段落边界切分
   - 其次在句子边界
   - 保持语义完整性

2. 参数选择
   - chunk_size: 500 字符
   - overlap: 100 字符
   - 经过实验对比选择

3. 特殊处理
   - 表格：整体作为一个 chunk
   - 代码：按函数/类切分
   - 标题：加入 chunk 作为上下文
```

```
Q: 检索用的什么相似度？为什么？

A:
主要用余弦相似度，原因：

1. 不受向量模长影响
   - 不同长度的文本公平对比
   - 避免长文本总是得分高

2. 计算高效
   - 归一化后只需点积
   - 支持批量计算

3. Embedding 模型通常针对余弦相似度优化

补充：在某些场景会用点积（如果 Embedding 已归一化）
```

```
Q: 如果用户问题和文档表述不一致怎么办？

A:
这是典型的语义 Gap 问题，解决方案：

1. Query Rewriting
   - 用 LLM 改写用户问题
   - 生成多个相关 query

2. Hypothetical Document Embedding (HyDE)
   - 让 LLM 先生成假设答案
   - 用假设答案去检索

3. Multi-Query
   - 生成多个角度的 query
   - 合并检索结果

4. 关键词 + 语义混合检索
   - BM25 捕捉关键词匹配
   - 向量检索捕捉语义
```

### Agent 问题

```
Q: Agent 和普通的 LLM 调用有什么区别？

A:
普通 LLM 调用：
- 单次输入 → 单次输出
- 能力受限于模型本身
- 无法获取实时信息

Agent：
- 可以多轮推理
- 可以调用外部工具
- 可以访问实时数据
- 可以分解复杂任务
- 有记忆和上下文管理

本质区别：Agent 让 LLM 从「回答问题」变成「解决问题」
```

```
Q: Agent 的工具调用失败了怎么办？

A:
我们设计了多层错误处理机制：

1. 重试机制
   - 自动重试 2-3 次
   - 指数退避

2. 错误反馈
   - 把错误信息返回给 Agent
   - 让它尝试其他方式

3. 降级策略
   - 用备选工具
   - 或直接用 LLM 能力兜底

4. 人工干预
   - 超过重试次数通知人工
   - 记录日志便于排查

5. 超时控制
   - 单个工具调用有超时
   - 整体任务有时间限制
```

---

## 项目深挖问题

```
Q: 你的项目里最有挑战的技术问题是什么？

回答思路：
1. 描述问题：具体、有难度
2. 分析过程：展示排查能力
3. 解决方案：技术细节
4. 效果验证：量化结果

示例：
"最有挑战的是检索召回率优化。

最初用默认配置，Recall@5 只有 68%，不满足上线要求。

排查发现两个问题：
1. 用户问法和文档表述差异大
2. 长文档被切分后语义不完整

解决方案：
1. 引入 Multi-Query，用 LLM 生成 3 个相关问题
2. 优化切分，增加上下文信息
3. 增加 Rerank 精排

最终 Recall@5 提升到 93%，提升了 25 个百分点。"
```

```
Q: 如果让你重新做这个项目，会有什么改进？

回答思路：
1. 诚实承认不足
2. 说明原因（时间/资源/认知）
3. 提出改进方案
4. 展示学习能力

示例：
"如果重做，我会在三个方面改进：

1. 更早引入评估体系
   当时是开发完才做评估，发现问题后返工。
   应该一开始就建立评估基准，迭代式优化。

2. 考虑 Hybrid Search
   我们只用了向量检索，后来发现关键词匹配有时更有效。
   应该一开始就用混合检索。

3. 更好的可观测性
   上线后发现问题难排查，缺少详细日志。
   应该设计好日志和追踪机制。"
```

```
Q: 你们的 QPS 是多少？怎么优化的？

示例回答：
"最终 QPS 达到 120，延迟 P99 < 500ms。

优化过程：

1. 基准测试：初始 QPS 30，瓶颈在 LLM 调用

2. 异步优化
   - 检索和预处理异步执行
   - LLM 调用使用异步客户端
   - QPS 提升到 50

3. 缓存优化
   - 相似问题结果缓存
   - Embedding 结果缓存
   - QPS 提升到 80

4. 并发优化
   - 增加 worker 数
   - 连接池优化
   - QPS 提升到 120

5. 最终方案
   - 4 核 8G 单机
   - 支持 120 QPS
   - 成本可控"
```

---

## 行为问题

```
Q: 说一个你在团队中解决冲突的例子

STAR 结构回答：

Situation：
"项目中，后端同事觉得我们的 RAG 方案太复杂，增加维护成本，
想用更简单的方案。"

Task：
"我需要说服他接受当前方案，同时也要考虑他的合理诉求。"

Action：
"我做了三件事：
1. 先了解他的具体顾虑，发现主要是担心运维复杂度
2. 用数据对比两个方案的效果差异（准确率相差 20%）
3. 提出折中方案：我负责写好文档和自动化脚本，降低运维成本"

Result：
"最终他接受了方案，我们也确实把运维工作简化了。
上线后效果很好，他还主动学习了 RAG 相关知识。"
```

```
Q: 你是怎么学习新技术的？

示例回答：
"我有一套系统的学习方法：

1. 先建立全局认知
   - 看官方文档的 Overview
   - 看几篇技术博客了解核心概念

2. 动手实践
   - 跑通官方示例
   - 做一个小项目
   - 边做边查文档

3. 深入理解
   - 读源码关键部分
   - 理解设计思想
   - 写总结博客

4. 实际应用
   - 在工作项目中使用
   - 遇到问题深入研究

比如学 LangChain，我花了两周：
第一周跑通 RAG 示例
第二周做一个小项目，写了篇博客
然后在工作中持续应用和深入。"
```

---

## 反问环节

```
技术相关：
- 团队目前在用什么技术栈？有计划引入新技术吗？
- 这个岗位主要负责哪个产品/方向？
- 团队有多少人？怎么分工的？

发展相关：
- 这个岗位的成长路径是怎样的？
- 团队有技术分享或学习机制吗？
- 对新人有什么期望？

业务相关：
- 产品目前处于什么阶段？
- 主要服务什么样的客户？
- 最近有什么技术挑战？
```

---

## ➡️ 下一步

继续 [09-复盘与规划.md](./09-复盘与规划.md)

