# ğŸ‘¥ é¡¹ç›®ï¼šç”¨æˆ·èšç±»ï¼ˆæ— ç›‘ç£ï¼‰

> å®Œæ•´çš„èšç±»é¡¹ç›®å®æˆ˜ï¼Œå®¢æˆ·ç»†åˆ†ä¸ç”»åƒ

---

## é¡¹ç›®æ¦‚è¿°

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®æ ‡** | å°†ç”¨æˆ·åˆ†æˆä¸åŒç¾¤ä½“ |
| **ç±»å‹** | æ— ç›‘ç£å­¦ä¹  - èšç±» |
| **æ•°æ®** | æ¨¡æ‹Ÿå®¢æˆ·æ•°æ® |
| **è¯„ä¼°** | è½®å»“ç³»æ•°ã€ä¸šåŠ¡è§£è¯» |

---

## å®Œæ•´ä»£ç 

```python
# ============================================================
# ç”¨æˆ·èšç±»é¡¹ç›® - å®Œæ•´ä»£ç 
# ============================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, silhouette_samples
from scipy.cluster.hierarchy import dendrogram, linkage
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['figure.figsize'] = (10, 6)
np.random.seed(42)

print("=" * 60)
print("1. æ•°æ®ç”Ÿæˆä¸åŠ è½½")
print("=" * 60)

# ç”Ÿæˆæ¨¡æ‹Ÿå®¢æˆ·æ•°æ®
n_customers = 500

# åˆ›å»ºä¸åŒç±»å‹çš„å®¢æˆ·
# ç±»å‹1ï¼šé«˜ä»·å€¼å®¢æˆ·ï¼ˆé«˜æ”¶å…¥ã€é«˜æ¶ˆè´¹ã€é«˜é¢‘ç‡ï¼‰
n1 = 100
type1 = pd.DataFrame({
    'Age': np.random.randint(35, 55, n1),
    'Annual_Income': np.random.randint(100000, 200000, n1),
    'Spending_Score': np.random.randint(70, 100, n1),
    'Purchase_Frequency': np.random.randint(30, 50, n1),
    'Avg_Transaction_Value': np.random.randint(300, 500, n1),
    'Membership_Years': np.random.randint(3, 10, n1)
})

# ç±»å‹2ï¼šå¹´è½»æ½œåŠ›å®¢æˆ·ï¼ˆå¹´è½»ã€ä¸­ç­‰æ”¶å…¥ã€é«˜æ¶ˆè´¹æ„æ„¿ï¼‰
n2 = 120
type2 = pd.DataFrame({
    'Age': np.random.randint(20, 35, n2),
    'Annual_Income': np.random.randint(40000, 80000, n2),
    'Spending_Score': np.random.randint(60, 90, n2),
    'Purchase_Frequency': np.random.randint(15, 35, n2),
    'Avg_Transaction_Value': np.random.randint(100, 250, n2),
    'Membership_Years': np.random.randint(1, 4, n2)
})

# ç±»å‹3ï¼šèŠ‚ä¿­å®¢æˆ·ï¼ˆå„å¹´é¾„æ®µã€ä½æ¶ˆè´¹ï¼‰
n3 = 150
type3 = pd.DataFrame({
    'Age': np.random.randint(25, 65, n3),
    'Annual_Income': np.random.randint(30000, 100000, n3),
    'Spending_Score': np.random.randint(10, 40, n3),
    'Purchase_Frequency': np.random.randint(5, 15, n3),
    'Avg_Transaction_Value': np.random.randint(50, 150, n3),
    'Membership_Years': np.random.randint(1, 8, n3)
})

# ç±»å‹4ï¼šè€å¹´ç¨³å®šå®¢æˆ·ï¼ˆå¹´é•¿ã€ä¸­ç­‰æ¶ˆè´¹ã€ç¨³å®šï¼‰
n4 = 130
type4 = pd.DataFrame({
    'Age': np.random.randint(50, 70, n4),
    'Annual_Income': np.random.randint(50000, 120000, n4),
    'Spending_Score': np.random.randint(40, 65, n4),
    'Purchase_Frequency': np.random.randint(10, 25, n4),
    'Avg_Transaction_Value': np.random.randint(150, 300, n4),
    'Membership_Years': np.random.randint(5, 15, n4)
})

# åˆå¹¶æ•°æ®
df = pd.concat([type1, type2, type3, type4], ignore_index=True)
df['CustomerID'] = range(1, len(df) + 1)

# æ·»åŠ ä¸€äº›å™ªå£°
for col in ['Spending_Score', 'Purchase_Frequency', 'Avg_Transaction_Value']:
    df[col] = df[col] + np.random.randint(-5, 6, len(df))
    df[col] = df[col].clip(1, None)

print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
print(f"\næ•°æ®é¢„è§ˆ:")
print(df.head(10))

print(f"\nç»Ÿè®¡ä¿¡æ¯:")
print(df.describe())

# ============================================================
print("\n" + "=" * 60)
print("2. æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA)")
print("=" * 60)

# é€‰æ‹©èšç±»ç‰¹å¾
features = ['Age', 'Annual_Income', 'Spending_Score',
            'Purchase_Frequency', 'Avg_Transaction_Value', 'Membership_Years']

# 2.1 ç‰¹å¾åˆ†å¸ƒ
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(features):
    axes[i].hist(df[col], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Frequency')
    axes[i].set_title(f'{col} Distribution')
    axes[i].axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.0f}')
    axes[i].legend()

plt.tight_layout()
plt.savefig('feature_distributions.png', dpi=150)
plt.show()

# 2.2 ç‰¹å¾ç›¸å…³æ€§
plt.figure(figsize=(10, 8))
corr = df[features].corr()
sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.savefig('correlation_matrix.png', dpi=150)
plt.show()

# 2.3 ç‰¹å¾æ•£ç‚¹å›¾
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

axes[0, 0].scatter(df['Annual_Income'], df['Spending_Score'], alpha=0.5, s=30)
axes[0, 0].set_xlabel('Annual Income')
axes[0, 0].set_ylabel('Spending Score')
axes[0, 0].set_title('Income vs Spending Score')

axes[0, 1].scatter(df['Age'], df['Spending_Score'], alpha=0.5, s=30)
axes[0, 1].set_xlabel('Age')
axes[0, 1].set_ylabel('Spending Score')
axes[0, 1].set_title('Age vs Spending Score')

axes[1, 0].scatter(df['Purchase_Frequency'], df['Avg_Transaction_Value'], alpha=0.5, s=30)
axes[1, 0].set_xlabel('Purchase Frequency')
axes[1, 0].set_ylabel('Avg Transaction Value')
axes[1, 0].set_title('Frequency vs Transaction Value')

axes[1, 1].scatter(df['Membership_Years'], df['Spending_Score'], alpha=0.5, s=30)
axes[1, 1].set_xlabel('Membership Years')
axes[1, 1].set_ylabel('Spending Score')
axes[1, 1].set_title('Membership vs Spending Score')

plt.tight_layout()
plt.savefig('feature_scatterplots.png', dpi=150)
plt.show()

# ============================================================
print("\n" + "=" * 60)
print("3. æ•°æ®é¢„å¤„ç†")
print("=" * 60)

# æå–ç‰¹å¾
X = df[features].copy()

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("æ ‡å‡†åŒ–å:")
print(f"  å‡å€¼: {X_scaled.mean(axis=0).round(4)}")
print(f"  æ ‡å‡†å·®: {X_scaled.std(axis=0).round(4)}")

# ============================================================
print("\n" + "=" * 60)
print("4. é€‰æ‹©æœ€ä½³èšç±»æ•°é‡")
print("=" * 60)

# 4.1 è‚˜éƒ¨æ³•åˆ™
K_range = range(2, 11)
inertias = []
silhouette_scores = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
    print(f"K={k}: Inertia={kmeans.inertia_:.0f}, Silhouette={silhouette_scores[-1]:.4f}")

# å¯è§†åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# è‚˜éƒ¨å›¾
axes[0].plot(K_range, inertias, 'bo-', linewidth=2)
axes[0].set_xlabel('Number of Clusters (K)')
axes[0].set_ylabel('Inertia')
axes[0].set_title('Elbow Method')
axes[0].grid(True, alpha=0.3)

# è½®å»“ç³»æ•°å›¾
axes[1].plot(K_range, silhouette_scores, 'go-', linewidth=2)
axes[1].set_xlabel('Number of Clusters (K)')
axes[1].set_ylabel('Silhouette Score')
axes[1].set_title('Silhouette Score Method')
axes[1].grid(True, alpha=0.3)

# æ ‡è®°æœ€ä½³ K
best_k = K_range[np.argmax(silhouette_scores)]
axes[1].axvline(best_k, color='red', linestyle='--', label=f'Best K = {best_k}')
axes[1].legend()

plt.tight_layout()
plt.savefig('optimal_k.png', dpi=150)
plt.show()

print(f"\næœ€ä½³ K (åŸºäºè½®å»“ç³»æ•°): {best_k}")

# ============================================================
print("\n" + "=" * 60)
print("5. K-Means èšç±»")
print("=" * 60)

# ä½¿ç”¨æœ€ä½³ K è¿›è¡Œèšç±»
optimal_k = 4  # å¯ä»¥æ ¹æ®è‚˜éƒ¨å›¾å’Œä¸šåŠ¡ç†è§£é€‰æ‹©
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_scaled)

print(f"é€‰æ‹© K = {optimal_k}")
print(f"è½®å»“ç³»æ•°: {silhouette_score(X_scaled, df['Cluster']):.4f}")

# å„èšç±»çš„æ ·æœ¬æ•°
print(f"\nå„èšç±»æ ·æœ¬æ•°:")
print(df['Cluster'].value_counts().sort_index())

# ============================================================
print("\n" + "=" * 60)
print("6. èšç±»ç»“æœå¯è§†åŒ–")
print("=" * 60)

# 6.1 ä½¿ç”¨ PCA é™ç»´å¯è§†åŒ–
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
df['PC1'] = X_pca[:, 0]
df['PC2'] = X_pca[:, 1]

print(f"PCA è§£é‡Šæ–¹å·®: {pca.explained_variance_ratio_.sum():.2%}")

# èšç±»å¯è§†åŒ–
plt.figure(figsize=(12, 8))
colors = ['red', 'blue', 'green', 'purple', 'orange']
for i in range(optimal_k):
    cluster_data = df[df['Cluster'] == i]
    plt.scatter(cluster_data['PC1'], cluster_data['PC2'],
                c=colors[i], label=f'Cluster {i}', alpha=0.6, s=50)

# èšç±»ä¸­å¿ƒ
centers_pca = pca.transform(kmeans.cluster_centers_)
plt.scatter(centers_pca[:, 0], centers_pca[:, 1],
            c='black', marker='X', s=300, edgecolors='white', linewidths=2, label='Centers')

plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
plt.title('Customer Segments (PCA Visualization)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('cluster_visualization.png', dpi=150)
plt.show()

# 6.2 å„ç‰¹å¾åœ¨ä¸åŒèšç±»ä¸­çš„åˆ†å¸ƒ
fig, axes = plt.subplots(2, 3, figsize=(16, 10))
axes = axes.flatten()

for i, col in enumerate(features):
    df.boxplot(column=col, by='Cluster', ax=axes[i])
    axes[i].set_title(f'{col} by Cluster')
    axes[i].set_xlabel('Cluster')
    axes[i].set_ylabel(col)

plt.suptitle('Feature Distribution by Cluster', y=1.02, fontsize=14)
plt.tight_layout()
plt.savefig('cluster_boxplots.png', dpi=150)
plt.show()

# ============================================================
print("\n" + "=" * 60)
print("7. èšç±»åˆ†æä¸å®¢æˆ·ç”»åƒ")
print("=" * 60)

# å„èšç±»çš„ç‰¹å¾å‡å€¼
cluster_summary = df.groupby('Cluster')[features].agg(['mean', 'std'])
print("å„èšç±»ç‰¹å¾ç»Ÿè®¡:")
print(df.groupby('Cluster')[features].mean().round(1))

# é›·è¾¾å›¾
def plot_radar(df, features, cluster_col):
    """ç»˜åˆ¶é›·è¾¾å›¾"""
    # å½’ä¸€åŒ–æ•°æ®
    cluster_means = df.groupby(cluster_col)[features].mean()
    normalized = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())

    # è®¾ç½®é›·è¾¾å›¾
    angles = np.linspace(0, 2 * np.pi, len(features), endpoint=False).tolist()
    angles += angles[:1]  # é—­åˆ

    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))

    colors = ['red', 'blue', 'green', 'purple', 'orange']
    for i, (idx, row) in enumerate(normalized.iterrows()):
        values = row.tolist()
        values += values[:1]
        ax.plot(angles, values, 'o-', linewidth=2, label=f'Cluster {idx}', color=colors[i])
        ax.fill(angles, values, alpha=0.1, color=colors[i])

    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(features, size=10)
    ax.set_title('Cluster Profiles (Radar Chart)', size=14)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

    plt.tight_layout()
    plt.savefig('cluster_radar.png', dpi=150)
    plt.show()

plot_radar(df, features, 'Cluster')

# å®¢æˆ·ç”»åƒ
print("\n" + "=" * 60)
print("å®¢æˆ·ç”»åƒåˆ†æ")
print("=" * 60)

cluster_profiles = df.groupby('Cluster')[features].mean()

for cluster in range(optimal_k):
    profile = cluster_profiles.loc[cluster]
    count = (df['Cluster'] == cluster).sum()
    pct = count / len(df) * 100

    print(f"\nã€Cluster {cluster}ã€‘- {count} äºº ({pct:.1f}%)")
    print("-" * 40)
    print(f"  å¹³å‡å¹´é¾„: {profile['Age']:.0f} å²")
    print(f"  å¹³å‡å¹´æ”¶å…¥: ${profile['Annual_Income']:,.0f}")
    print(f"  æ¶ˆè´¹è¯„åˆ†: {profile['Spending_Score']:.0f}")
    print(f"  è´­ä¹°é¢‘ç‡: {profile['Purchase_Frequency']:.0f} æ¬¡/æœˆ")
    print(f"  å¹³å‡å®¢å•ä»·: ${profile['Avg_Transaction_Value']:.0f}")
    print(f"  ä¼šå‘˜å¹´é™: {profile['Membership_Years']:.1f} å¹´")

    # è‡ªåŠ¨ç”Ÿæˆç”»åƒæè¿°
    if profile['Spending_Score'] > 70 and profile['Annual_Income'] > 100000:
        print("  ğŸ‘‰ ç”»åƒ: é«˜ä»·å€¼å®¢æˆ· (VIP)")
    elif profile['Age'] < 35 and profile['Spending_Score'] > 60:
        print("  ğŸ‘‰ ç”»åƒ: å¹´è½»é«˜æ½œåŠ›å®¢æˆ·")
    elif profile['Spending_Score'] < 40:
        print("  ğŸ‘‰ ç”»åƒ: ä»·æ ¼æ•æ„Ÿå‹å®¢æˆ·")
    elif profile['Age'] > 50 and profile['Membership_Years'] > 5:
        print("  ğŸ‘‰ ç”»åƒ: æˆç†Ÿç¨³å®šå®¢æˆ·")
    else:
        print("  ğŸ‘‰ ç”»åƒ: ä¸€èˆ¬å®¢æˆ·")

# ============================================================
print("\n" + "=" * 60)
print("8. ä¸šåŠ¡å»ºè®®")
print("=" * 60)

print("""
åŸºäºèšç±»åˆ†æçš„ä¸šåŠ¡å»ºè®®ï¼š

1. é«˜ä»·å€¼å®¢æˆ· (VIP)ï¼š
   - æä¾›ä¸“å±æœåŠ¡å’Œä¼˜æƒ 
   - å»ºç«‹ VIP ä¼šå‘˜ä½“ç³»
   - ä¼˜å…ˆæ¨é€é«˜ç«¯äº§å“

2. å¹´è½»é«˜æ½œåŠ›å®¢æˆ·ï¼š
   - ç¤¾äº¤åª’ä½“è¥é”€
   - æ½®æµäº§å“æ¨è
   - åˆ†æœŸä»˜æ¬¾ä¼˜æƒ 

3. ä»·æ ¼æ•æ„Ÿå‹å®¢æˆ·ï¼š
   - ä¿ƒé”€æ´»åŠ¨é€šçŸ¥
   - ä¼˜æƒ åˆ¸å‘æ”¾
   - æ€§ä»·æ¯”äº§å“æ¨è

4. æˆç†Ÿç¨³å®šå®¢æˆ·ï¼š
   - å¿ è¯šåº¦å¥–åŠ±
   - é•¿æœŸä¼šå‘˜ä¼˜æƒ 
   - ç¨³å®šçš„æœåŠ¡è´¨é‡

æ•°æ®é©±åŠ¨çš„ç²¾å‡†è¥é”€å¯ä»¥æ˜¾è‘—æé«˜è½¬åŒ–ç‡ï¼
""")

# ============================================================
print("\n" + "=" * 60)
print("9. å…¶ä»–èšç±»æ–¹æ³•å¯¹æ¯”")
print("=" * 60)

# DBSCAN
dbscan = DBSCAN(eps=1.5, min_samples=10)
df['DBSCAN_Cluster'] = dbscan.fit_predict(X_scaled)
n_clusters_dbscan = len(set(df['DBSCAN_Cluster'])) - (1 if -1 in df['DBSCAN_Cluster'] else 0)
print(f"DBSCAN: {n_clusters_dbscan} ä¸ªèšç±», {(df['DBSCAN_Cluster'] == -1).sum()} ä¸ªå™ªå£°ç‚¹")

# å±‚æ¬¡èšç±»
agg = AgglomerativeClustering(n_clusters=optimal_k)
df['Hierarchical_Cluster'] = agg.fit_predict(X_scaled)

# å¯¹æ¯”å¯è§†åŒ–
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for ax, cluster_col, title in zip(axes,
    ['Cluster', 'DBSCAN_Cluster', 'Hierarchical_Cluster'],
    ['K-Means', 'DBSCAN', 'Hierarchical']):
    scatter = ax.scatter(df['PC1'], df['PC2'], c=df[cluster_col], cmap='viridis', alpha=0.6, s=30)
    ax.set_xlabel('PC1')
    ax.set_ylabel('PC2')
    ax.set_title(title)
    plt.colorbar(scatter, ax=ax)

plt.tight_layout()
plt.savefig('clustering_comparison.png', dpi=150)
plt.show()

# ============================================================
print("\n" + "=" * 60)
print("10. ä¿å­˜ç»“æœ")
print("=" * 60)

# ä¿å­˜èšç±»ç»“æœ
output_df = df[['CustomerID'] + features + ['Cluster']]
output_df.to_csv('customer_segments.csv', index=False)
print("èšç±»ç»“æœå·²ä¿å­˜åˆ° customer_segments.csv")

# ä¿å­˜èšç±»æ‘˜è¦
summary = df.groupby('Cluster')[features].agg(['mean', 'std', 'count'])
summary.to_csv('cluster_summary.csv')
print("èšç±»æ‘˜è¦å·²ä¿å­˜åˆ° cluster_summary.csv")

print("\né¡¹ç›®å®Œæˆï¼")
```

---

## æ‰©å±•ä»»åŠ¡

- [ ] å°è¯•ä¸åŒçš„ç‰¹å¾ç»„åˆ
- [ ] ä½¿ç”¨ t-SNE/UMAP å¯è§†åŒ–
- [ ] æ·»åŠ æ—¶åºç‰¹å¾ï¼ˆå¦‚æœ€è¿‘è´­ä¹°æ—¶é—´ï¼‰
- [ ] è®¡ç®—æ¯ä¸ªèšç±»çš„ CLVï¼ˆå®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼‰
- [ ] æ„å»ºå®¢æˆ·æµå¤±é¢„è­¦æ¨¡å‹

