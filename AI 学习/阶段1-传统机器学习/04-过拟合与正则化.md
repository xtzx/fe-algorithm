# ğŸ“Š 04 - è¿‡æ‹Ÿåˆä¸æ­£åˆ™åŒ–

> æœ¬æ–‡è¯¦ç»†ä»‹ç»è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆçš„æ¦‚å¿µåŠè§£å†³æ–¹æ³•

---

## ç›®å½•

1. [è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ](#1-è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ)
2. [åå·®-æ–¹å·®æƒè¡¡](#2-åå·®-æ–¹å·®æƒè¡¡)
3. [æ­£åˆ™åŒ–æ–¹æ³•](#3-æ­£åˆ™åŒ–æ–¹æ³•)
4. [äº¤å‰éªŒè¯](#4-äº¤å‰éªŒè¯)
5. [å…¶ä»–é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•](#5-å…¶ä»–é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•)
6. [ç»ƒä¹ é¢˜](#6-ç»ƒä¹ é¢˜)

---

## 1. è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ

### 1.1 åŸºæœ¬æ¦‚å¿µ

```
æ¬ æ‹Ÿåˆï¼ˆUnderfittingï¼‰          è¿‡æ‹Ÿåˆï¼ˆOverfittingï¼‰
- æ¨¡å‹å¤ªç®€å•                    - æ¨¡å‹å¤ªå¤æ‚
- è®­ç»ƒè¯¯å·®é«˜                    - è®­ç»ƒè¯¯å·®ä½
- æµ‹è¯•è¯¯å·®é«˜                    - æµ‹è¯•è¯¯å·®é«˜
- é«˜åå·®ï¼ˆHigh Biasï¼‰           - é«˜æ–¹å·®ï¼ˆHigh Varianceï¼‰
```

### 1.2 å¯è§†åŒ–ç†è§£

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# ç”Ÿæˆæ•°æ®
np.random.seed(42)
n_samples = 30
X = np.sort(np.random.rand(n_samples) * 10).reshape(-1, 1)
y = np.sin(X).ravel() + np.random.randn(n_samples) * 0.3

# ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹
degrees = [1, 4, 15]
titles = ['Underfitting (degree=1)', 'Good Fit (degree=4)', 'Overfitting (degree=15)']

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

X_plot = np.linspace(0, 10, 100).reshape(-1, 1)

for ax, degree, title in zip(axes, degrees, titles):
    # åˆ›å»ºå¤šé¡¹å¼å›å½’æ¨¡å‹
    model = make_pipeline(
        PolynomialFeatures(degree),
        LinearRegression()
    )
    model.fit(X, y)

    # é¢„æµ‹
    y_pred_train = model.predict(X)
    y_pred_plot = model.predict(X_plot)

    # è®¡ç®—è¯¯å·®
    train_mse = mean_squared_error(y, y_pred_train)

    # ç»˜å›¾
    ax.scatter(X, y, color='blue', s=30, label='Training data')
    ax.plot(X_plot, y_pred_plot, color='red', linewidth=2, label='Model')
    ax.plot(X_plot, np.sin(X_plot), color='green', linewidth=2, linestyle='--', label='True function')

    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.set_title(f'{title}\nTrain MSE: {train_mse:.4f}')
    ax.legend()
    ax.set_ylim(-2, 2)

plt.tight_layout()
plt.show()
```

### 1.3 å­¦ä¹ æ›²çº¿

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.datasets import make_regression

# ç”Ÿæˆæ•°æ®
X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)

def plot_learning_curve(model, X, y, title):
    """ç»˜åˆ¶å­¦ä¹ æ›²çº¿"""
    train_sizes, train_scores, val_scores = learning_curve(
        model, X, y,
        train_sizes=np.linspace(0.1, 1.0, 10),
        cv=5,
        scoring='neg_mean_squared_error'
    )

    # è½¬æ¢ä¸ºæ­£çš„ MSE
    train_scores = -train_scores
    val_scores = -val_scores

    train_mean = train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)

    plt.figure(figsize=(8, 6))
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='orange')
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training error')
    plt.plot(train_sizes, val_mean, 'o-', color='orange', label='Validation error')

    plt.xlabel('Training Set Size')
    plt.ylabel('MSE')
    plt.title(title)
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

# æ¬ æ‹Ÿåˆæ¨¡å‹
model_underfit = LinearRegression()
plot_learning_curve(model_underfit, X, y, 'Learning Curve - Linear Model')

# è¿‡æ‹Ÿåˆæ¨¡å‹
model_overfit = make_pipeline(PolynomialFeatures(15), LinearRegression())
plot_learning_curve(model_overfit, X, y, 'Learning Curve - Polynomial (degree=15)')
```

**å­¦ä¹ æ›²çº¿è§£è¯»**ï¼š
- **æ¬ æ‹Ÿåˆ**ï¼šè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½å¾ˆé«˜ï¼Œä¸”å·®è·å°
- **è¿‡æ‹Ÿåˆ**ï¼šè®­ç»ƒè¯¯å·®ä½ï¼ŒéªŒè¯è¯¯å·®é«˜ï¼Œå·®è·å¤§
- **è‰¯å¥½æ‹Ÿåˆ**ï¼šä¸¤æ¡æ›²çº¿æœ€ç»ˆæ”¶æ•›åˆ°ä¸€ä¸ªè¾ƒä½çš„å€¼

### 1.4 æ£€æµ‹è¿‡æ‹Ÿåˆ

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# ç”Ÿæˆæ•°æ®
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ä¸åŒå¤æ‚åº¦çš„æ¨¡å‹
max_depths = [2, 5, 10, 20, None]  # None è¡¨ç¤ºä¸é™åˆ¶æ·±åº¦

print("Max Depth\tTrain Acc\tTest Acc\tGap")
print("-" * 50)

for max_depth in max_depths:
    model = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=42)
    model.fit(X_train, y_train)

    train_acc = accuracy_score(y_train, model.predict(X_train))
    test_acc = accuracy_score(y_test, model.predict(X_test))
    gap = train_acc - test_acc

    depth_str = str(max_depth) if max_depth else 'None'
    print(f"{depth_str}\t\t{train_acc:.4f}\t\t{test_acc:.4f}\t\t{gap:.4f}")

# å½“ Gap å¾ˆå¤§æ—¶ï¼Œè¯´æ˜è¿‡æ‹Ÿåˆ
```

---

## 2. åå·®-æ–¹å·®æƒè¡¡

### 2.1 æ¦‚å¿µ

```
æ€»è¯¯å·® = åå·®Â² + æ–¹å·® + å™ªå£°

åå·®ï¼ˆBiasï¼‰ï¼š
  - æ¨¡å‹çš„é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®è·
  - é«˜åå·® â†’ æ¬ æ‹Ÿåˆ
  - åŸå› ï¼šæ¨¡å‹å‡è®¾å¤ªç®€å•

æ–¹å·®ï¼ˆVarianceï¼‰ï¼š
  - æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„æ•æ„Ÿç¨‹åº¦
  - é«˜æ–¹å·® â†’ è¿‡æ‹Ÿåˆ
  - åŸå› ï¼šæ¨¡å‹å‡è®¾å¤ªå¤æ‚

å™ªå£°ï¼ˆNoiseï¼‰ï¼š
  - æ•°æ®æœ¬èº«çš„éšæœºæ€§
  - æ— æ³•å‡å°‘
```

### 2.2 å¯è§†åŒ–

```python
import numpy as np
import matplotlib.pyplot as plt

# æ¨¡æ‹Ÿåå·®-æ–¹å·®æƒè¡¡
complexity = np.linspace(1, 20, 100)

# åå·®éšå¤æ‚åº¦å¢åŠ è€Œå‡å°‘
bias = 1 / complexity

# æ–¹å·®éšå¤æ‚åº¦å¢åŠ è€Œå¢åŠ 
variance = 0.1 * complexity

# å™ªå£°å›ºå®š
noise = 0.5

# æ€»è¯¯å·®
total_error = bias + variance + noise

plt.figure(figsize=(10, 6))
plt.plot(complexity, bias, 'b-', linewidth=2, label='BiasÂ²')
plt.plot(complexity, variance, 'r-', linewidth=2, label='Variance')
plt.plot(complexity, [noise]*len(complexity), 'g--', linewidth=2, label='Noise')
plt.plot(complexity, total_error, 'k-', linewidth=3, label='Total Error')

# æœ€ä¼˜ç‚¹
optimal_idx = np.argmin(total_error)
plt.axvline(complexity[optimal_idx], color='gray', linestyle='--', alpha=0.7)
plt.scatter([complexity[optimal_idx]], [total_error[optimal_idx]],
            color='black', s=100, zorder=5, label='Optimal')

plt.xlabel('Model Complexity', fontsize=12)
plt.ylabel('Error', fontsize=12)
plt.title('Bias-Variance Tradeoff', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# æ ‡æ³¨åŒºåŸŸ
plt.annotate('Underfitting\n(High Bias)', xy=(3, 0.8), fontsize=10, ha='center')
plt.annotate('Overfitting\n(High Variance)', xy=(17, 2), fontsize=10, ha='center')

plt.show()
```

---

## 3. æ­£åˆ™åŒ–æ–¹æ³•

### 3.1 L2 æ­£åˆ™åŒ–ï¼ˆRidgeï¼‰

```python
from sklearn.linear_model import Ridge
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# ç”Ÿæˆæ•°æ®
X, y = make_regression(n_samples=100, n_features=20, n_informative=5, noise=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ä¸åŒæ­£åˆ™åŒ–å¼ºåº¦
alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]
train_errors = []
test_errors = []
coef_norms = []

for alpha in alphas:
    model = Ridge(alpha=alpha)
    model.fit(X_train, y_train)

    train_errors.append(mean_squared_error(y_train, model.predict(X_train)))
    test_errors.append(mean_squared_error(y_test, model.predict(X_test)))
    coef_norms.append(np.linalg.norm(model.coef_))

# å¯è§†åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# è¯¯å·® vs alpha
axes[0].semilogx(alphas, train_errors, 'b-o', label='Train MSE')
axes[0].semilogx(alphas, test_errors, 'r-o', label='Test MSE')
axes[0].set_xlabel('Alpha (Regularization Strength)')
axes[0].set_ylabel('MSE')
axes[0].set_title('Ridge: Error vs Alpha')
axes[0].legend()
axes[0].grid(True)

# ç³»æ•°èŒƒæ•° vs alpha
axes[1].semilogx(alphas, coef_norms, 'g-o')
axes[1].set_xlabel('Alpha (Regularization Strength)')
axes[1].set_ylabel('||Coefficients||')
axes[1].set_title('Ridge: Coefficient Norm vs Alpha')
axes[1].grid(True)

plt.tight_layout()
plt.show()

# æœ€ä½³ alpha
best_alpha = alphas[np.argmin(test_errors)]
print(f"æœ€ä½³ Alpha: {best_alpha}")
```

**L2 æ­£åˆ™åŒ–åŸç†**ï¼š

$$\text{Loss} = \text{MSE} + \alpha \sum_{j=1}^{p} w_j^2$$

- æƒ©ç½šå¤§çš„ç³»æ•°
- ç³»æ•°ä¼šå˜å°ä½†ä¸ä¼šå˜æˆ 0
- é€‚åˆï¼šç‰¹å¾éƒ½æœ‰ä¸€å®šä½œç”¨

### 3.2 L1 æ­£åˆ™åŒ–ï¼ˆLassoï¼‰

```python
from sklearn.linear_model import Lasso
import numpy as np
import matplotlib.pyplot as plt

# ä½¿ç”¨ç›¸åŒæ•°æ®
alphas = [0.001, 0.01, 0.1, 1, 10]
coefs = []

for alpha in alphas:
    model = Lasso(alpha=alpha, max_iter=10000)
    model.fit(X_train, y_train)
    coefs.append(model.coef_)

# å¯è§†åŒ–ç³»æ•°è·¯å¾„
plt.figure(figsize=(10, 6))
coefs = np.array(coefs)

for i in range(coefs.shape[1]):
    plt.semilogx(alphas, coefs[:, i], '-o', linewidth=1, markersize=3)

plt.xlabel('Alpha (Regularization Strength)')
plt.ylabel('Coefficient Value')
plt.title('Lasso: Coefficient Paths')
plt.axhline(0, color='black', linestyle='--', alpha=0.3)
plt.grid(True)
plt.show()

# å±•ç¤ºç¨€ç–æ€§
print("\nä¸åŒ Alpha ä¸‹éé›¶ç³»æ•°æ•°é‡:")
for alpha in alphas:
    model = Lasso(alpha=alpha, max_iter=10000)
    model.fit(X_train, y_train)
    n_nonzero = np.sum(model.coef_ != 0)
    print(f"Alpha = {alpha}: {n_nonzero}/{len(model.coef_)} ä¸ªéé›¶ç³»æ•°")
```

**L1 æ­£åˆ™åŒ–åŸç†**ï¼š

$$\text{Loss} = \text{MSE} + \alpha \sum_{j=1}^{p} |w_j|$$

- äº§ç”Ÿç¨€ç–è§£ï¼ˆéƒ¨åˆ†ç³»æ•°ä¸º 0ï¼‰
- æœ‰ç‰¹å¾é€‰æ‹©æ•ˆæœ
- é€‚åˆï¼šé«˜ç»´æ•°æ®ã€éœ€è¦ç‰¹å¾é€‰æ‹©

### 3.3 ElasticNetï¼ˆL1 + L2ï¼‰

```python
from sklearn.linear_model import ElasticNet

# ElasticNet = L1 + L2
model = ElasticNet(
    alpha=1.0,       # æ€»æ­£åˆ™åŒ–å¼ºåº¦
    l1_ratio=0.5,    # L1 æ¯”ä¾‹ (0=Ridge, 1=Lasso)
    max_iter=10000
)
model.fit(X_train, y_train)

print(f"éé›¶ç³»æ•°: {np.sum(model.coef_ != 0)}/{len(model.coef_)}")
print(f"Test MSE: {mean_squared_error(y_test, model.predict(X_test)):.4f}")

# æ¯”è¾ƒä¸åŒ l1_ratio
l1_ratios = [0, 0.25, 0.5, 0.75, 1.0]
for ratio in l1_ratios:
    model = ElasticNet(alpha=0.1, l1_ratio=ratio, max_iter=10000)
    model.fit(X_train, y_train)
    n_nonzero = np.sum(model.coef_ != 0)
    test_mse = mean_squared_error(y_test, model.predict(X_test))
    print(f"l1_ratio={ratio}: éé›¶ç³»æ•°={n_nonzero}, Test MSE={test_mse:.4f}")
```

**ElasticNet åŸç†**ï¼š

$$\text{Loss} = \text{MSE} + \alpha \cdot l1\_ratio \sum |w_j| + \alpha \cdot (1-l1\_ratio) \sum w_j^2$$

### 3.4 æ­£åˆ™åŒ–å¯¹æ¯”

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

models = {
    'Linear Regression': LinearRegression(),
    'Ridge (Î±=1)': Ridge(alpha=1),
    'Lasso (Î±=0.1)': Lasso(alpha=0.1, max_iter=10000),
    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)
}

results = []
for name, model in models.items():
    model.fit(X_train, y_train)

    train_mse = mean_squared_error(y_train, model.predict(X_train))
    test_mse = mean_squared_error(y_test, model.predict(X_test))
    r2 = r2_score(y_test, model.predict(X_test))
    n_nonzero = np.sum(model.coef_ != 0) if hasattr(model, 'coef_') else '-'

    results.append({
        'Model': name,
        'Train MSE': train_mse,
        'Test MSE': test_mse,
        'RÂ²': r2,
        'Non-zero Coefs': n_nonzero
    })

df_results = pd.DataFrame(results)
print(df_results.to_string(index=False))
```

---

## 4. äº¤å‰éªŒè¯

### 4.1 K-Fold äº¤å‰éªŒè¯

```python
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
import numpy as np

# ç”Ÿæˆæ•°æ®
X, y = make_classification(n_samples=500, n_features=20, random_state=42)

# åˆ›å»ºæ¨¡å‹
model = LogisticRegression(max_iter=1000)

# K-Fold äº¤å‰éªŒè¯
k_folds = [3, 5, 10]

for k in k_folds:
    scores = cross_val_score(model, X, y, cv=k, scoring='accuracy')
    print(f"{k}-Fold CV: {scores.mean():.4f} Â± {scores.std():.4f}")
    print(f"  å„æŠ˜å¾—åˆ†: {scores}")
    print()
```

### 4.2 å¯è§†åŒ– K-Fold

```python
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import numpy as np

n_samples = 20
n_splits = 5

kf = KFold(n_splits=n_splits, shuffle=False)

fig, ax = plt.subplots(figsize=(12, 4))

for i, (train_idx, val_idx) in enumerate(kf.split(range(n_samples))):
    # è®­ç»ƒé›†
    ax.scatter(train_idx, [i] * len(train_idx),
               c='blue', marker='s', s=100, label='Train' if i == 0 else '')
    # éªŒè¯é›†
    ax.scatter(val_idx, [i] * len(val_idx),
               c='red', marker='s', s=100, label='Validation' if i == 0 else '')

ax.set_yticks(range(n_splits))
ax.set_yticklabels([f'Fold {i+1}' for i in range(n_splits)])
ax.set_xlabel('Sample Index')
ax.set_title('K-Fold Cross Validation (K=5)')
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### 4.3 åˆ†å±‚ K-Foldï¼ˆStratifiedKFoldï¼‰

```python
from sklearn.model_selection import StratifiedKFold, cross_val_score
import numpy as np

# ä¸å¹³è¡¡æ•°æ®
y_imbalanced = np.array([0]*90 + [1]*10)
X_imbalanced = np.random.randn(100, 5)

# æ™®é€š KFold
kf = KFold(n_splits=5, shuffle=True, random_state=42)
print("æ™®é€š KFold å„æŠ˜æ­£æ ·æœ¬æ¯”ä¾‹:")
for i, (train_idx, val_idx) in enumerate(kf.split(X_imbalanced)):
    print(f"  Fold {i+1}: {y_imbalanced[val_idx].mean():.2%}")

# åˆ†å±‚ KFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
print("\nåˆ†å±‚ KFold å„æŠ˜æ­£æ ·æœ¬æ¯”ä¾‹:")
for i, (train_idx, val_idx) in enumerate(skf.split(X_imbalanced, y_imbalanced)):
    print(f"  Fold {i+1}: {y_imbalanced[val_idx].mean():.2%}")
```

### 4.4 ç•™ä¸€æ³•ï¼ˆLOOCVï¼‰

```python
from sklearn.model_selection import LeaveOneOut, cross_val_score
from sklearn.linear_model import LogisticRegression

# å°æ•°æ®é›†
X_small = np.random.randn(50, 5)
y_small = np.random.randint(0, 2, 50)

model = LogisticRegression(max_iter=1000)

# LOOCV
loo = LeaveOneOut()
scores = cross_val_score(model, X_small, y_small, cv=loo)

print(f"LOOCV: {scores.mean():.4f} Â± {scores.std():.4f}")
print(f"æ€»å…± {len(scores)} æ¬¡éªŒè¯")
```

### 4.5 ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©è¶…å‚æ•°

```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
import matplotlib.pyplot as plt
import numpy as np

# æ•°æ®
from sklearn.datasets import make_regression
X, y = make_regression(n_samples=200, n_features=20, noise=10, random_state=42)

# ä¸åŒ alpha çš„äº¤å‰éªŒè¯å¾—åˆ†
alphas = np.logspace(-4, 4, 50)
cv_scores = []

for alpha in alphas:
    model = Ridge(alpha=alpha)
    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
    cv_scores.append(-scores.mean())

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.semilogx(alphas, cv_scores, 'b-o')
plt.xlabel('Alpha')
plt.ylabel('Cross-Validation MSE')
plt.title('Ridge: CV Score vs Alpha')
plt.grid(True)

# æœ€ä½³ alpha
best_idx = np.argmin(cv_scores)
best_alpha = alphas[best_idx]
plt.axvline(best_alpha, color='red', linestyle='--', label=f'Best Î± = {best_alpha:.4f}')
plt.legend()
plt.show()

print(f"æœ€ä½³ Alpha: {best_alpha:.4f}")
print(f"æœ€ä½³ CV MSE: {cv_scores[best_idx]:.4f}")
```

---

## 5. å…¶ä»–é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•

### 5.1 å¢åŠ è®­ç»ƒæ•°æ®

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
from sklearn.model_selection import learning_curve

# ç”Ÿæˆå¤§æ•°æ®é›†
X, y = make_classification(n_samples=2000, n_features=20, random_state=42)

model = LogisticRegression(max_iter=1000)

train_sizes, train_scores, val_scores = learning_curve(
    model, X, y,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5
)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_scores.mean(axis=1), 'b-o', label='Train')
plt.plot(train_sizes, val_scores.mean(axis=1), 'r-o', label='Validation')
plt.fill_between(train_sizes,
                 train_scores.mean(axis=1) - train_scores.std(axis=1),
                 train_scores.mean(axis=1) + train_scores.std(axis=1),
                 alpha=0.1, color='blue')
plt.fill_between(train_sizes,
                 val_scores.mean(axis=1) - val_scores.std(axis=1),
                 val_scores.mean(axis=1) + val_scores.std(axis=1),
                 alpha=0.1, color='red')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve: More Data Reduces Overfitting')
plt.legend()
plt.grid(True)
plt.show()
```

### 5.2 ç‰¹å¾é€‰æ‹©

```python
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score

# ç”Ÿæˆé«˜ç»´æ•°æ®
X, y = make_classification(n_samples=500, n_features=100, n_informative=10, random_state=42)

# åŸå§‹ç‰¹å¾
model = RandomForestClassifier(n_estimators=100, random_state=42)
scores_original = cross_val_score(model, X, y, cv=5)
print(f"åŸå§‹ç‰¹å¾ ({X.shape[1]}): {scores_original.mean():.4f}")

# åŸºäºæ¨¡å‹çš„ç‰¹å¾é€‰æ‹©
selector = SelectFromModel(
    RandomForestClassifier(n_estimators=100, random_state=42),
    threshold='median'
)
X_selected = selector.fit_transform(X, y)
scores_selected = cross_val_score(model, X_selected, y, cv=5)
print(f"é€‰æ‹©åç‰¹å¾ ({X_selected.shape[1]}): {scores_selected.mean():.4f}")
```

### 5.3 æ—©åœï¼ˆEarly Stoppingï¼‰

```python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

# æ•°æ®
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒå¹¶è®°å½•æ¯è½®çš„æŸå¤±
model = GradientBoostingClassifier(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=3,
    random_state=42,
    validation_fraction=0.2,
    n_iter_no_change=10  # æ—©åœ
)

model.fit(X_train, y_train)

# æŸ¥çœ‹å®é™…è®­ç»ƒäº†å¤šå°‘è½®
print(f"å®é™…è®­ç»ƒè½®æ•°: {model.n_estimators_}")

# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
train_scores = []
test_scores = []

for i, y_pred in enumerate(model.staged_predict(X_train)):
    train_scores.append((y_pred == y_train).mean())

for i, y_pred in enumerate(model.staged_predict(X_test)):
    test_scores.append((y_pred == y_test).mean())

plt.figure(figsize=(10, 6))
plt.plot(train_scores, 'b-', label='Train')
plt.plot(test_scores, 'r-', label='Test')
plt.axvline(model.n_estimators_, color='green', linestyle='--', label='Early Stop')
plt.xlabel('Boosting Iterations')
plt.ylabel('Accuracy')
plt.title('Early Stopping')
plt.legend()
plt.grid(True)
plt.show()
```

### 5.4 Dropoutï¼ˆç”¨äºæ ‘æ¨¡å‹ï¼‰

```python
from sklearn.ensemble import RandomForestClassifier

# max_features: æ¯æ¬¡åˆ†è£‚è€ƒè™‘çš„æœ€å¤§ç‰¹å¾æ•°
# ç±»ä¼¼äº Dropout çš„æ•ˆæœ

model_full = RandomForestClassifier(
    n_estimators=100,
    max_features=None,  # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾
    random_state=42
)

model_sqrt = RandomForestClassifier(
    n_estimators=100,
    max_features='sqrt',  # ä½¿ç”¨ sqrt(n_features) ä¸ªç‰¹å¾
    random_state=42
)

model_log2 = RandomForestClassifier(
    n_estimators=100,
    max_features='log2',  # ä½¿ç”¨ log2(n_features) ä¸ªç‰¹å¾
    random_state=42
)

from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score

X, y = make_classification(n_samples=500, n_features=50, random_state=42)

for name, model in [('å…¨éƒ¨ç‰¹å¾', model_full), ('sqrtç‰¹å¾', model_sqrt), ('log2ç‰¹å¾', model_log2)]:
    scores = cross_val_score(model, X, y, cv=5)
    print(f"{name}: {scores.mean():.4f} Â± {scores.std():.4f}")
```

---

## 6. ç»ƒä¹ é¢˜

### åŸºç¡€ç»ƒä¹ 

1. ç»˜åˆ¶å­¦ä¹ æ›²çº¿ï¼Œåˆ¤æ–­æ¨¡å‹æ˜¯è¿‡æ‹Ÿåˆè¿˜æ˜¯æ¬ æ‹Ÿåˆ
2. æ¯”è¾ƒ Ridge å’Œ Lasso åœ¨åŒä¸€æ•°æ®é›†ä¸Šçš„è¡¨ç°
3. ä½¿ç”¨ 5-Fold äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹

### è¿›é˜¶ç»ƒä¹ 

4. ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹© Ridge çš„æœ€ä½³ alpha
5. å¯¹ä¸€ä¸ªé«˜ç»´æ•°æ®é›†ï¼Œä½¿ç”¨ Lasso è¿›è¡Œç‰¹å¾é€‰æ‹©

### å‚è€ƒç­”æ¡ˆ

<details>
<summary>ç»ƒä¹  4 å‚è€ƒç­”æ¡ˆ</summary>

```python
from sklearn.linear_model import RidgeCV
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# ç”Ÿæˆæ•°æ®
X, y = make_regression(n_samples=200, n_features=20, noise=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# RidgeCV è‡ªåŠ¨é€‰æ‹©æœ€ä½³ alpha
alphas = [0.001, 0.01, 0.1, 1, 10, 100]
model = RidgeCV(alphas=alphas, cv=5)
model.fit(X_train, y_train)

print(f"æœ€ä½³ Alpha: {model.alpha_}")
print(f"Test RÂ²: {model.score(X_test, y_test):.4f}")
```

</details>

---

## â¡ï¸ ä¸‹ä¸€æ­¥

å­¦å®Œæœ¬èŠ‚åï¼Œç»§ç»­å­¦ä¹  [05-çº¿æ€§æ¨¡å‹.md](./05-çº¿æ€§æ¨¡å‹.md)

